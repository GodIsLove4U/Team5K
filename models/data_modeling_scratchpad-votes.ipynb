{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import numpy\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# From dependency imports\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score,r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sqlalchemy import create_engine\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure settings for Relational Database Service, and defining database info in config variable.\n",
    "jdbc_url=\"jdbc:postgresql://34.67.52.115/team5k\"\n",
    "config = {'user': 'postgres', \n",
    "          \"password\": \"team5kteam5k\", \n",
    "          \"driver\":\"org.postgresql.Driver\",\n",
    "          \"location\": \"34.67.52.115\",\n",
    "          \"db\": \"team5k\",\n",
    "          \"port\": \"5432\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Flag to print Informational message\n",
    "dmdebug=True\n",
    "\n",
    "### Creating variable holding postgres info in format \"postgres://[user]:[password]@[location]:[port]/[database]\".\n",
    "create_engine_str = ('postgresql://' \n",
    "                     + config[\"user\"] \n",
    "                     + \":\" + config[\"password\"] \n",
    "                     + \"@\" + config[\"location\"] \n",
    "                     + \":\" + config[\"port\"] \n",
    "                     + \"/\" + config[\"db\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance.\n",
    "engine = create_engine(create_engine_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['committees', 'candidates', 'education', 'committee_summary_2020', 'six_state_donations', 'donations', 'fec_donor_az', 'health_metrics', 'birth_death_rate', 'postal_codes', 'fec_donor_mi', 'fec_donor_wi', 'fec_committee', 'fec_donor_pa', 'agg_county_votes', 'agg_county_donors', 'pres_votes_6t', 'unemployment', 'fec_donor_nc', 'fec_donor_fl']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names. \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>blue_votes</th>\n",
       "      <th>red_votes</th>\n",
       "      <th>other_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>election_year</th>\n",
       "      <th>PopPct_Urban</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>PopDen_Urban</th>\n",
       "      <th>PopPct_Rural</th>\n",
       "      <th>PopDen_Rural</th>\n",
       "      <th>winning_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13025</td>\n",
       "      <td>5947</td>\n",
       "      <td>484</td>\n",
       "      <td>19456</td>\n",
       "      <td>Apache</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2000</td>\n",
       "      <td>25.94</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1080.7</td>\n",
       "      <td>74.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13360</td>\n",
       "      <td>18180</td>\n",
       "      <td>1701</td>\n",
       "      <td>33241</td>\n",
       "      <td>Cochise</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2000</td>\n",
       "      <td>63.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1933.4</td>\n",
       "      <td>36.30</td>\n",
       "      <td>7.8</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20280</td>\n",
       "      <td>17562</td>\n",
       "      <td>3041</td>\n",
       "      <td>40883</td>\n",
       "      <td>Coconino</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2000</td>\n",
       "      <td>68.53</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1939.8</td>\n",
       "      <td>31.47</td>\n",
       "      <td>2.3</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7700</td>\n",
       "      <td>9158</td>\n",
       "      <td>878</td>\n",
       "      <td>17736</td>\n",
       "      <td>Gila</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2000</td>\n",
       "      <td>58.94</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>41.06</td>\n",
       "      <td>4.6</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3355</td>\n",
       "      <td>6007</td>\n",
       "      <td>302</td>\n",
       "      <td>9664</td>\n",
       "      <td>Graham</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2000</td>\n",
       "      <td>53.56</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1430.2</td>\n",
       "      <td>46.44</td>\n",
       "      <td>3.8</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>10845</td>\n",
       "      <td>13213</td>\n",
       "      <td>594</td>\n",
       "      <td>24652</td>\n",
       "      <td>Tuscola</td>\n",
       "      <td>MI</td>\n",
       "      <td>2000</td>\n",
       "      <td>15.84</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1333.3</td>\n",
       "      <td>84.16</td>\n",
       "      <td>58.9</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>13796</td>\n",
       "      <td>14792</td>\n",
       "      <td>894</td>\n",
       "      <td>29482</td>\n",
       "      <td>Van Buren</td>\n",
       "      <td>MI</td>\n",
       "      <td>2000</td>\n",
       "      <td>29.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1030.5</td>\n",
       "      <td>70.86</td>\n",
       "      <td>92.2</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>86647</td>\n",
       "      <td>52459</td>\n",
       "      <td>5834</td>\n",
       "      <td>144940</td>\n",
       "      <td>Washtenaw</td>\n",
       "      <td>MI</td>\n",
       "      <td>2000</td>\n",
       "      <td>83.55</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2131.4</td>\n",
       "      <td>16.45</td>\n",
       "      <td>99.3</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>530414</td>\n",
       "      <td>223021</td>\n",
       "      <td>15192</td>\n",
       "      <td>768627</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>MI</td>\n",
       "      <td>2000</td>\n",
       "      <td>99.30</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3301.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>196.3</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>5326</td>\n",
       "      <td>7215</td>\n",
       "      <td>441</td>\n",
       "      <td>12982</td>\n",
       "      <td>Wexford</td>\n",
       "      <td>MI</td>\n",
       "      <td>2000</td>\n",
       "      <td>35.71</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1337.6</td>\n",
       "      <td>64.29</td>\n",
       "      <td>37.8</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  blue_votes  red_votes  other_votes  total_votes     county state  \\\n",
       "0       0       13025       5947          484        19456     Apache    AZ   \n",
       "1       0       13360      18180         1701        33241    Cochise    AZ   \n",
       "2       0       20280      17562         3041        40883   Coconino    AZ   \n",
       "3       0        7700       9158          878        17736       Gila    AZ   \n",
       "4       0        3355       6007          302         9664     Graham    AZ   \n",
       "..    ...         ...        ...          ...          ...        ...   ...   \n",
       "93      0       10845      13213          594        24652    Tuscola    MI   \n",
       "94      0       13796      14792          894        29482  Van Buren    MI   \n",
       "95      0       86647      52459         5834       144940  Washtenaw    MI   \n",
       "96      0      530414     223021        15192       768627      Wayne    MI   \n",
       "97      0        5326       7215          441        12982    Wexford    MI   \n",
       "\n",
       "    election_year  PopPct_Urban  Unemployment  PopDen_Urban  PopPct_Rural  \\\n",
       "0            2000         25.94           9.0        1080.7         74.06   \n",
       "1            2000         63.70           4.5        1933.4         36.30   \n",
       "2            2000         68.53           4.4        1939.8         31.47   \n",
       "3            2000         58.94           5.2        1625.0         41.06   \n",
       "4            2000         53.56           5.4        1430.2         46.44   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "93           2000         15.84           4.7        1333.3         84.16   \n",
       "94           2000         29.14           4.1        1030.5         70.86   \n",
       "95           2000         83.55           2.4        2131.4         16.45   \n",
       "96           2000         99.30           3.9        3301.7          0.70   \n",
       "97           2000         35.71           5.5        1337.6         64.29   \n",
       "\n",
       "    PopDen_Rural winning_party  \n",
       "0            4.7      democrat  \n",
       "1            7.8    republican  \n",
       "2            2.3      democrat  \n",
       "3            4.6    republican  \n",
       "4            3.8    republican  \n",
       "..           ...           ...  \n",
       "93          58.9    republican  \n",
       "94          92.2    republican  \n",
       "95          99.3      democrat  \n",
       "96         196.3      democrat  \n",
       "97          37.8    republican  \n",
       "\n",
       "[98 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get voter data\n",
    "votes_df = pd.read_sql_query('select * from \"agg_county_votes\"',con=engine)\n",
    "votes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index              int64\n",
      "blue_votes         int64\n",
      "red_votes          int64\n",
      "other_votes        int64\n",
      "total_votes        int64\n",
      "county            object\n",
      "state             object\n",
      "election_year      int64\n",
      "PopPct_Urban     float64\n",
      "Unemployment     float64\n",
      "PopDen_Urban     float64\n",
      "PopPct_Rural     float64\n",
      "PopDen_Rural     float64\n",
      "winning_party     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look at column info\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(votes_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of     index  blue_votes  red_votes  other_votes  total_votes     county state  \\\n",
       "0       0       13025       5947          484        19456     Apache    AZ   \n",
       "1       0       13360      18180         1701        33241    Cochise    AZ   \n",
       "2       0       20280      17562         3041        40883   Coconino    AZ   \n",
       "3       0        7700       9158          878        17736       Gila    AZ   \n",
       "4       0        3355       6007          302         9664     Graham    AZ   \n",
       "..    ...         ...        ...          ...          ...        ...   ...   \n",
       "93      0       10845      13213          594        24652    Tuscola    MI   \n",
       "94      0       13796      14792          894        29482  Van Buren    MI   \n",
       "95      0       86647      52459         5834       144940  Washtenaw    MI   \n",
       "96      0      530414     223021        15192       768627      Wayne    MI   \n",
       "97      0        5326       7215          441        12982    Wexford    MI   \n",
       "\n",
       "    election_year  PopPct_Urban  Unemployment  PopDen_Urban  PopPct_Rural  \\\n",
       "0            2000         25.94           9.0        1080.7         74.06   \n",
       "1            2000         63.70           4.5        1933.4         36.30   \n",
       "2            2000         68.53           4.4        1939.8         31.47   \n",
       "3            2000         58.94           5.2        1625.0         41.06   \n",
       "4            2000         53.56           5.4        1430.2         46.44   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "93           2000         15.84           4.7        1333.3         84.16   \n",
       "94           2000         29.14           4.1        1030.5         70.86   \n",
       "95           2000         83.55           2.4        2131.4         16.45   \n",
       "96           2000         99.30           3.9        3301.7          0.70   \n",
       "97           2000         35.71           5.5        1337.6         64.29   \n",
       "\n",
       "    PopDen_Rural winning_party  \n",
       "0            4.7      democrat  \n",
       "1            7.8    republican  \n",
       "2            2.3      democrat  \n",
       "3            4.6    republican  \n",
       "4            3.8    republican  \n",
       "..           ...           ...  \n",
       "93          58.9    republican  \n",
       "94          92.2    republican  \n",
       "95          99.3      democrat  \n",
       "96         196.3      democrat  \n",
       "97          37.8    republican  \n",
       "\n",
       "[98 rows x 14 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the Aggregate Votes dataset\n",
    "votes_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'blue_votes', 'red_votes', 'other_votes', 'total_votes',\n",
       "       'county', 'state', 'election_year', 'PopPct_Urban', 'Unemployment',\n",
       "       'PopDen_Urban', 'PopPct_Rural', 'PopDen_Rural', 'winning_party'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index of column names in the Aggregate Votes dataset\n",
    "votes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column index has 0 null values\n",
      "Column blue_votes has 0 null values\n",
      "Column red_votes has 0 null values\n",
      "Column other_votes has 0 null values\n",
      "Column total_votes has 0 null values\n",
      "Column county has 0 null values\n",
      "Column state has 0 null values\n",
      "Column election_year has 0 null values\n",
      "Column PopPct_Urban has 0 null values\n",
      "Column Unemployment has 0 null values\n",
      "Column PopDen_Urban has 12 null values\n",
      "Column PopPct_Rural has 0 null values\n",
      "Column PopDen_Rural has 0 null values\n",
      "Column winning_party has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Find null values in these data\n",
    "for column in votes_df.columns:\n",
    "    print(f\"Column {column} has {votes_df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI    83\n",
       "AZ    15\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the total_votes value counts to prepare for binning/bucketing\n",
    "###Determine what column to choose\n",
    "total_votes = votes_df.state.value_counts()\n",
    "total_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x213dee7ee48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the total_votes value counts\n",
    "###Change once appropriate column is chosen\n",
    "total_votes.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county           98\n",
       "state             2\n",
       "winning_party     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "votes_cat = votes_df.dtypes[votes_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "votes_df[votes_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numeric and categorical values\n",
    "numeric_columns = ['blue_votes', 'red_votes', 'other_votes', 'total_votes', 'election_year',\n",
    "                   'PopPct_Urban', 'Unemployment','PopDen_Urban', 'PopPct_Rural',\n",
    "                   'PopDen_Rural']\n",
    "\n",
    "category_columns = ['county', 'state','winning_party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue_votes</th>\n",
       "      <th>red_votes</th>\n",
       "      <th>other_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>election_year</th>\n",
       "      <th>PopPct_Urban</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>PopDen_Urban</th>\n",
       "      <th>PopPct_Rural</th>\n",
       "      <th>PopDen_Rural</th>\n",
       "      <th>...</th>\n",
       "      <th>county_Van Buren</th>\n",
       "      <th>county_Washtenaw</th>\n",
       "      <th>county_Wayne</th>\n",
       "      <th>county_Wexford</th>\n",
       "      <th>county_Yavapai</th>\n",
       "      <th>county_Yuma</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_MI</th>\n",
       "      <th>winning_party_democrat</th>\n",
       "      <th>winning_party_republican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13025</td>\n",
       "      <td>5947</td>\n",
       "      <td>484</td>\n",
       "      <td>19456</td>\n",
       "      <td>2000</td>\n",
       "      <td>25.94</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1080.7</td>\n",
       "      <td>74.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13360</td>\n",
       "      <td>18180</td>\n",
       "      <td>1701</td>\n",
       "      <td>33241</td>\n",
       "      <td>2000</td>\n",
       "      <td>63.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1933.4</td>\n",
       "      <td>36.30</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20280</td>\n",
       "      <td>17562</td>\n",
       "      <td>3041</td>\n",
       "      <td>40883</td>\n",
       "      <td>2000</td>\n",
       "      <td>68.53</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1939.8</td>\n",
       "      <td>31.47</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7700</td>\n",
       "      <td>9158</td>\n",
       "      <td>878</td>\n",
       "      <td>17736</td>\n",
       "      <td>2000</td>\n",
       "      <td>58.94</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>41.06</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3355</td>\n",
       "      <td>6007</td>\n",
       "      <td>302</td>\n",
       "      <td>9664</td>\n",
       "      <td>2000</td>\n",
       "      <td>53.56</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1430.2</td>\n",
       "      <td>46.44</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10845</td>\n",
       "      <td>13213</td>\n",
       "      <td>594</td>\n",
       "      <td>24652</td>\n",
       "      <td>2000</td>\n",
       "      <td>15.84</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1333.3</td>\n",
       "      <td>84.16</td>\n",
       "      <td>58.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>13796</td>\n",
       "      <td>14792</td>\n",
       "      <td>894</td>\n",
       "      <td>29482</td>\n",
       "      <td>2000</td>\n",
       "      <td>29.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1030.5</td>\n",
       "      <td>70.86</td>\n",
       "      <td>92.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>86647</td>\n",
       "      <td>52459</td>\n",
       "      <td>5834</td>\n",
       "      <td>144940</td>\n",
       "      <td>2000</td>\n",
       "      <td>83.55</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2131.4</td>\n",
       "      <td>16.45</td>\n",
       "      <td>99.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>530414</td>\n",
       "      <td>223021</td>\n",
       "      <td>15192</td>\n",
       "      <td>768627</td>\n",
       "      <td>2000</td>\n",
       "      <td>99.30</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3301.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>196.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5326</td>\n",
       "      <td>7215</td>\n",
       "      <td>441</td>\n",
       "      <td>12982</td>\n",
       "      <td>2000</td>\n",
       "      <td>35.71</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1337.6</td>\n",
       "      <td>64.29</td>\n",
       "      <td>37.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    blue_votes  red_votes  other_votes  total_votes  election_year  \\\n",
       "0        13025       5947          484        19456           2000   \n",
       "1        13360      18180         1701        33241           2000   \n",
       "2        20280      17562         3041        40883           2000   \n",
       "3         7700       9158          878        17736           2000   \n",
       "4         3355       6007          302         9664           2000   \n",
       "..         ...        ...          ...          ...            ...   \n",
       "93       10845      13213          594        24652           2000   \n",
       "94       13796      14792          894        29482           2000   \n",
       "95       86647      52459         5834       144940           2000   \n",
       "96      530414     223021        15192       768627           2000   \n",
       "97        5326       7215          441        12982           2000   \n",
       "\n",
       "    PopPct_Urban  Unemployment  PopDen_Urban  PopPct_Rural  PopDen_Rural  ...  \\\n",
       "0          25.94           9.0        1080.7         74.06           4.7  ...   \n",
       "1          63.70           4.5        1933.4         36.30           7.8  ...   \n",
       "2          68.53           4.4        1939.8         31.47           2.3  ...   \n",
       "3          58.94           5.2        1625.0         41.06           4.6  ...   \n",
       "4          53.56           5.4        1430.2         46.44           3.8  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "93         15.84           4.7        1333.3         84.16          58.9  ...   \n",
       "94         29.14           4.1        1030.5         70.86          92.2  ...   \n",
       "95         83.55           2.4        2131.4         16.45          99.3  ...   \n",
       "96         99.30           3.9        3301.7          0.70         196.3  ...   \n",
       "97         35.71           5.5        1337.6         64.29          37.8  ...   \n",
       "\n",
       "    county_Van Buren  county_Washtenaw  county_Wayne  county_Wexford  \\\n",
       "0                  0                 0             0               0   \n",
       "1                  0                 0             0               0   \n",
       "2                  0                 0             0               0   \n",
       "3                  0                 0             0               0   \n",
       "4                  0                 0             0               0   \n",
       "..               ...               ...           ...             ...   \n",
       "93                 0                 0             0               0   \n",
       "94                 1                 0             0               0   \n",
       "95                 0                 1             0               0   \n",
       "96                 0                 0             1               0   \n",
       "97                 0                 0             0               1   \n",
       "\n",
       "    county_Yavapai  county_Yuma  state_AZ  state_MI  winning_party_democrat  \\\n",
       "0                0            0         1         0                       1   \n",
       "1                0            0         1         0                       0   \n",
       "2                0            0         1         0                       1   \n",
       "3                0            0         1         0                       0   \n",
       "4                0            0         1         0                       0   \n",
       "..             ...          ...       ...       ...                     ...   \n",
       "93               0            0         0         1                       0   \n",
       "94               0            0         0         1                       0   \n",
       "95               0            0         0         1                       1   \n",
       "96               0            0         0         1                       1   \n",
       "97               0            0         0         1                       0   \n",
       "\n",
       "    winning_party_republican  \n",
       "0                          0  \n",
       "1                          1  \n",
       "2                          0  \n",
       "3                          1  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "93                         1  \n",
       "94                         1  \n",
       "95                         0  \n",
       "96                         0  \n",
       "97                         1  \n",
       "\n",
       "[86 rows x 100 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create X value\n",
    "X = votes_df[numeric_columns].merge(pd.get_dummies(votes_df[category_columns]), left_index=True, right_index=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "###le = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "\n",
    "###votes_encoded_df = votes_df.apply(le.fit_transform)\n",
    "###votes_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "#encode_df = pd.DataFrame(enc.fit_transform(nn_df[votes_mi_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "#encode_df.columns = enc.get_feature_names(votes_mi_cat)\n",
    "#encode_df.head()\n",
    "###X = votes_encoded_df\n",
    "###X.columns.to_list()\n",
    "X = X.fillna(0)\n",
    "y = votes_df['total_votes']\n",
    "###X.isnull().sum().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a y series from Transactions column\n",
    "###y = X[\"total_votes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and testing sets\n",
    "###X = X.drop(\"total_votes\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler or MinMax Scaler instance\n",
    "###scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "#X_scaler = scaler.fit(X_train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the length of the X_train info\n",
    "###len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dcohen\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "nn_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\", input_dim = len(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 20,401\n",
      "Trainable params: 20,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 5ms/sample - loss: 32004126976.0000\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32004099072.0000\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32004079104.0000\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32004059136.0000\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 32004044352.0000\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32004016128.0000\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32004000768.0000\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003976192.0000\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 32003950592.0000\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 116us/sample - loss: 32003932160.0000\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003904512.0000\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003876864.0000\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003851520.0000\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 32003816192.0000\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32003789312.0000\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003760128.0000\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 93us/sample - loss: 32003730432.0000\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003694592.0000\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003657728.0000\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003618816.0000\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003575808.0000\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32003535872.0000\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003494912.0000\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003438592.0000\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003396608.0000\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 93us/sample - loss: 32003340288.0000\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003290112.0000\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003231744.0000\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003167232.0000\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32003106816.0000\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003041280.0000\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32002967168.0000\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32002908160.0000\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32002839552.0000\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32002767872.0000\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32002690048.0000\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32002619904.0000\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32002520576.0000\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32002447360.0000\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32002362368.0000\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32002275328.0000\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 32002170496.0000\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32002098176.0000\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 32001978624.0000\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32001890304.0000\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32001788928.0000\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32001683456.0000\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32001581056.0000\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 32001481728.0000\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32001346560.0000\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32001250304.0000\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32001136640.0000\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32001012736.0000\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 37653397504.000 - 0s 140us/sample - loss: 32000893952.0000\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32000768000.0000\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32000623104.0000\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 32000497664.0000\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32000370688.0000\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32000239616.0000\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32000118784.0000\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 545us/sample - loss: 31999972352.0000\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31999820800.0000\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 31999674368.0000\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31999525888.0000\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31999400576.0000\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31999223808.0000\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31999075328.0000\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31998904320.0000\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31998766592.0000\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 117us/sample - loss: 31998573568.0000\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31998404096.0000\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31998255104.0000\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31998084096.0000\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31997900800.0000\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31997710336.0000\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31997543424.0000\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 31997343488.0000\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31997203200.0000\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31997002240.0000\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31996807168.0000\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31996630528.0000\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 31996432384.0000\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31996210176.0000\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 31996032256.0000\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31995822080.0000\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31995580416.0000\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/sample - loss: 31995398144.0000\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31995160448.0000\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31994988544.0000\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31994757120.0000\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31994530304.0000\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 31994319872.0000\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31994109952.0000\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 109us/sample - loss: 31993902592.0000\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 94us/sample - loss: 31993655296.0000\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31993391104.0000\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 31993186304.0000\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31992930816.0000\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31992710144.0000\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31992509184.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x213df70d848>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(X_train_scaled, np.asarray(y_train), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = nn_model.predict(X_train_scaled)\n",
    "y_test_pred = nn_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2111105706120795"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.45981961620046463"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\", input_dim = len(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(tf.keras.layers.Dense(units=len(X.columns) * 2, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 60,601\n",
      "Trainable params: 60,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 7ms/sample - loss: 32004088832.0000\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 32004035584.0000\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32003985152.0000\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 32003936256.0000\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32003879936.0000\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 32003823552.0000\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 32003742720.0000\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 32003641856.0000\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32003540992.0000\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 32003419136.0000\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32003274752.0000\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 32003100672.0000\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 32002924544.0000\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32002703360.0000\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 32002413568.0000\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32002121728.0000\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 32001799168.0000\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32001491968.0000\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 32000999424.0000\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32000519168.0000\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 32000006144.0000\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31999413248.0000\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31998603904.0000\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31998003200.0000\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31997256320.0000\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 623us/sample - loss: 31996205056.0000\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31995285504.0000\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 608us/sample - loss: 31994162176.0000\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31992966656.0000\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31991668736.0000\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31990056960.0000\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31988496384.0000\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 31986781184.0000\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 31984913408.0000\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31982811136.0000\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31980853248.0000\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31977882624.0000\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31976029184.0000\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31972603136.0000\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31970179072.0000\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31967187968.0000\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31964041216.0000\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31960443904.0000\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31956804608.0000\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 31953616128.0000\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31948461056.0000\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31945105408.0000\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31940379648.0000\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31935220736.0000\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31930965504.0000\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31924748288.0000\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 31919820800.0000\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - ETA: 0s - loss: 30720921600.000 - 0s 343us/sample - loss: 31913548800.0000\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31907263488.0000\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31900848128.0000\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31894742016.0000\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 31886225920.0000\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31879384576.0000\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31872895488.0000\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31864169472.0000\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31856601088.0000\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 31846772736.0000\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31838089216.0000\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31828892672.0000\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31819450368.0000\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31807519488.0000\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31798579200.0000\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31788144640.0000\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31775766528.0000\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31763587584.0000\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 31752274944.0000\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31738650624.0000\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31725564928.0000\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31715015424.0000\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31700956160.0000\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31684909056.0000\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31671438336.0000\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31655284736.0000\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31637877760.0000\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31624046592.0000\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 31607414784.0000\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31592979328.0000\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31572501504.0000\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31555140608.0000\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31536027648.0000\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 125us/sample - loss: 31517683712.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31495144320.0000\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31476607488.0000\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31461144064.0000\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31437693952.0000\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31415558144.0000\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 31392848896.0000\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 31368487232.0000\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31350558720.0000\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 31328905984.0000\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31305236736.0000\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31276409856.0000\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31254784000.0000\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 31224082432.0000\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 31201716224.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x213e0b2df88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train_scaled, np.asarray(y_train), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = deep_model.predict(X_train_scaled)\n",
    "y_test_pred = deep_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1804679001536318"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3762422595187309"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "###number_input_features = len(X_train_scaled[0])\n",
    "###hidden_nodes_layer1 =  8\n",
    "###hidden_nodes_layer2 = 5\n",
    "\n",
    "###nn.add(\n",
    "    ###tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    "    ###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second hidden layer\n",
    "###nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "###nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the model\n",
    "###nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using the \"adam\" optimizer and \"mean_squared_error\" or \"mean_absolute_error\" loss function\n",
    "#nn.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "###nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model for 100 epochs.\n",
    "###fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model info summary\n",
    "###model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "###print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values for the train and test sets\n",
    "###y_pred = nn.predict(X_test_scaled)\n",
    "###y_pred_train = nn.predict(X_train_scaled)\n",
    "###y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the training predictions with r2_score()\n",
    "###r2_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
