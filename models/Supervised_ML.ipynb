{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from consts import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(CREATE_ENGINE_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'committee_summary_2020', 'donations', 'agg_county_votes', 'agg_county_donors', 'fec_donor_az', 'health_metrics', 'birth_death_rate', 'postal_codes', 'fec_donor_mi', 'fec_donor_wi', 'fec_committee', 'fec_donor_pa', 'pres_votes_6t', 'unemployment', 'fec_donor_nc', 'fec_donor_fl']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_tuples = state_tuple[0]    \n",
    "    donor_tuples = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_tuples)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_tuples[i]\n",
    "        donor_tuple = donor_tuples[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_tuple)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_votes_linear_regression(df):\n",
    "    print(df.head())\n",
    "    #Will run a separate LR model on each of the SML_params\n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"blue_amt\", \"red_amt\", \"county\", \"state_donors\", \"election_year_votes\", \"PopPct_Urban\", \"Unemployment\", \"PopDen_Urban\", \"PopPct_Rural\", \"PopDen_Rural\"]\n",
    "    #Set all the votes cols of interest\n",
    "    votes_cols = [\"blue_votes\", \"red_votes\", \"other_votes\", \"total_votes\", \"percent_blue_votes\", \"percent_red_votes\", \"percent_other_votes\", \"county\", \"state_donors\", \"election_year_votes\", \"PopPct_Urban\", \"Unemployment\", \"PopDen_Urban\", \"PopPct_Rural\", \"PopDen_Rural\"]\n",
    "    #Set all the donors cols of interest\n",
    "    donors_cols = [\"blue_amt\", \"red_amt\", \"other_amt\", \"total_amt\", \"percent_blue_votes\", \"percent_red_votes\", \"percent_other_votes\"]\n",
    "    \n",
    "    sml_cols = votes_cols + donors_cols\n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df):\n",
    "    sml_params = [\"transaction_amt\", \"employer\", \"occupation\", \"entity_tp\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"entity_tp\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"entity_tp\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type):\n",
    "    #Reduce columns to start with\n",
    "    #print(df.head())\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "        \n",
    "        #Run Linear Regression Model on X,y\n",
    "        #Set Y column to just the ML model\n",
    "        y_df = select_columns(df, [sml_param])   \n",
    "        y_df = y_df.fillna(0)\n",
    "        y_df = label_enc(y_df)\n",
    "        y = y_df[sml_param].values\n",
    "    \n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        x_cols = sml_cols.copy()\n",
    "        print(f\"sml param{sml_param}\")\n",
    "        \n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        X_df = label_enc(X_df)\n",
    "        X = X_df[x_cols].values\n",
    "        \n",
    "        if model_type == 'linear':\n",
    "            print(f\"Running a Linear Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y, x_cols)\n",
    "        elif model_type == 'logistic':\n",
    "            print(f\"Running a Logistics Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE, stratify=y)\n",
    "    \n",
    "    classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    #Scale the values\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    #Predict the values based on the X test values\n",
    "    predictions = classifier.predict(X_test_scaled)\n",
    "    \n",
    "    score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y, x_cols):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE)\n",
    "    model = LinearRegression()\n",
    "    #Train the model \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Scale the values\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    #Predict the values based on the X test values\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "    print(\"Prediction!!\")\n",
    "    print(\"Confusion Matrix!!\")    \n",
    "    #Cast to int for the confusion matrix\n",
    "    y_test = [int(i) for i in y_test]\n",
    "    y_pred = [int(i) for i in y_pred]\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    print(\"Classificaiton Report!!\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(X, y, y_pred):\n",
    "    print(\"X=\" + str(len(X)))\n",
    "    print(X)\n",
    "    print(\"y=\" + str(len(y)))\n",
    "    print(y)\n",
    "    print(\"y_pred\" + str(len(y_pred)))\n",
    "    print(y_pred)\n",
    "    \n",
    "    plt.scatter(X, y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def query_all(table_name):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    select_sql = 'select * from {}'.format(table_name)\n",
    "    df = pd.read_sql_query(select_sql,con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state, engine):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    donor_table_name = '\"fec_donor_{}\"'.format(state.lower())    \n",
    "    donor_select_sql = 'select * from {}'.format(donor_table_name)\n",
    "    donor_df = pd.read_sql_query(donor_select_sql,con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    agg_donors_df = query_all(TABLE_AGG_DONORS)\n",
    "    agg_votes_df = query_all(TABLE_AGG_VOTES)\n",
    "    merged_df = agg_donors_df.merge(agg_votes_df, left_on='county', right_on='county', suffixes=(\"_donors\", \"_votes\"))\n",
    "    #Run a linear regression analysis on the merged dataset\n",
    "    donation_votes_linear_regression(merged_df)\n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)\n",
    "    \n",
    "    #Loop through each state and run separate LR models on each state.\n",
    "    for state in SWING_STATES:\n",
    "        donor_df = donor_state_query(state, engine)\n",
    "        #Run the machine learning models on the donation set\n",
    "        donation_linear_regression(donor_df)\n",
    "        \n",
    "        #TODO Once we have full dataset, then enable logistic regression\n",
    "        #donation_logistic_regression(donor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index_donors  blue_amt  red_amt  other_amt  total_amt  percent_blue_donors  \\\n",
      "0             0         0   111500          0     111500                  0.0   \n",
      "1             0         0   111500          0     111500                  0.0   \n",
      "2             0         0   111500          0     111500                  0.0   \n",
      "3             0         0   111500          0     111500                  0.0   \n",
      "4             0         0   111500          0     111500                  0.0   \n",
      "\n",
      "   percent_red_donors  percent_other_donors    county state_donors  ...  \\\n",
      "0                 1.0                   0.0  Maricopa           AZ  ...   \n",
      "1                 1.0                   0.0  Maricopa           AZ  ...   \n",
      "2                 1.0                   0.0  Maricopa           AZ  ...   \n",
      "3                 1.0                   0.0  Maricopa           AZ  ...   \n",
      "4                 1.0                   0.0  Maricopa           AZ  ...   \n",
      "\n",
      "   percent_blue_votes  percent_red_votes  percent_other_votes  state_votes  \\\n",
      "0            0.428838           0.532292             0.038870           AZ   \n",
      "1            0.423264           0.569654             0.007082           AZ   \n",
      "2            0.441160           0.546864             0.011977           AZ   \n",
      "3            0.437532           0.544754             0.017714           AZ   \n",
      "4            0.448330           0.476684             0.074986           AZ   \n",
      "\n",
      "   election_year_votes  PopPct_Urban  Unemployment  PopDen_Urban  \\\n",
      "0                 2000         97.64           3.2        3117.1   \n",
      "1                 2004         97.64           4.4        3117.1   \n",
      "2                 2008         97.64           5.4        3117.1   \n",
      "3                 2012         97.64           7.3        3117.1   \n",
      "4                 2016         97.64           4.6        3117.1   \n",
      "\n",
      "   PopPct_Rural PopDen_Rural  \n",
      "0          2.36         11.3  \n",
      "1          2.36         11.3  \n",
      "2          2.36         11.3  \n",
      "3          2.36         11.3  \n",
      "4          2.36         11.3  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "sml paramblue_votes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-3635fba85cf6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_donors_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_votes_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'county'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_donors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_votes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Run a linear regression analysis on the merged dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdonation_votes_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#TODO: Now with all states donations and voting results aggregated, predict the number of votes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#predict_votes_linear_regression(state_model_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ce4b97a62032>\u001b[0m in \u001b[0;36mdonation_votes_linear_regression\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msml_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdonors_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#Run some machine learning models on the donation of the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrun_linear_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-da8753a1ea1a>\u001b[0m in \u001b[0;36mrun_linear_regression_params\u001b[0;34m(df, sml_params, sml_cols)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_linear_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_sml_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-ae5fd8858bd7>\u001b[0m in \u001b[0;36mrun_sml_params\u001b[0;34m(df, sml_params, sml_cols, model_type)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"sml param{sml_param}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msml_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mX_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mX_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
