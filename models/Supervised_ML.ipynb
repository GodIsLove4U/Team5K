{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from consts import *\n",
    "from sklearn.svm import SVC\n",
    "from gcloud import storage\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(CREATE_ENGINE_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['committees', 'candidates', 'education', 'res_lr', 'res_log', 'six_state_donations', 'donations', 'health_metrics', 'agg_county_votes', 'birth_death_rate', 'postal_codes', 'agg_county_donors', 'pres_votes_6t', 'unemployment']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_tuples = state_tuple[0]    \n",
    "    donor_tuples = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_tuples)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_tuples[i]\n",
    "        donor_tuple = donor_tuples[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_tuple)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_votes_linear_regression(df):\n",
    "    #Will run a separate LR model on each of the SML_params\n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"blue_amt\", \"red_amt\", \"blue_num\", \"red_num\"]\n",
    "    #Set all the votes cols of interest\n",
    "    votes_cols = [\"blue_votes\", \"red_votes\", \"total_votes\", \"county\", \"state\", \"election_year\", \"PopPct_Urban\", \"Unemployment\", \"PopDen_Urban\", \"PopPct_Rural\", \"PopDen_Rural\", \"winning_party\"]\n",
    "    #Set all the donors cols of interest\n",
    "    donors_cols = [\"blue_amt\", \"red_amt\", \"total_amt\", \"blue_num\", \"red_num\"]\n",
    "    \n",
    "    sml_cols = votes_cols + donors_cols\n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(df, sml_params, sml_cols, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df, state):\n",
    "    sml_params = [\"TRANSACTION_AMT\"]\n",
    "    sml_cols = [\"CITY\", \"STATE\", \"ZIP\", \"EMPLOYER\", \"OCCUPATION\", \"TRANSACTION_AMT\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df, state):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"CITY\", \"STATE\", \"ZIP\", \"EMPLOYER\", \"OCCUPATION\", \"TRANSACTION_AMT\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_svc_linear_regression(donor_df, state):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"CITY\", \"STATE\", \"ZIP\", \"EMPLOYER\", \"OCCUPATION\", \"TRANSACTION_AMT\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_svc_linear_params(donor_df, sml_params, sml_cols, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type, state):\n",
    "    #Reduce columns to start with\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "                \n",
    "        y_df = select_columns(df, [sml_param])\n",
    "        y_df = y_df.fillna(0)\n",
    "        y_df = label_enc(y_df)\n",
    "        y = y_df[sml_param].values\n",
    "        \n",
    "        x_cols = sml_cols.copy()\n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        X_df = label_enc(X_df)\n",
    "        X = X_df[x_cols].values\n",
    "            \n",
    "        if model_type == 'linear':\n",
    "            #Run Linear Regression Model on X,y\n",
    "            #Set Y column to just the ML model\n",
    "\n",
    "            print(f\"Running a Linear Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y, sml_param, state)\n",
    "        elif model_type == 'logistic':\n",
    "            print(f\"Running a Logistics Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            \n",
    "            data_scaler = StandardScaler()\n",
    "            y_df_scaled = data_scaler.fit_transform(y_df)\n",
    "            X_df_scaled = data_scaler.fit_transform(X_df)\n",
    "            \n",
    "            X = X_df[x_cols].values\n",
    "            y = y_df[sml_param].values\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y, state, sml_param)\n",
    "        #elif model_type == 'svc linear':\n",
    "            #print(f\"Running a SVC Linear Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            #run_svc_regression(X, y, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svc_linear_params(df, sml_params, sml_cols, state):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"svc linear\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols, state):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols, state):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svc_regression(X, y, state):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE, stratify=y)\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model_type = \"SVC Linear\"\n",
    "    \n",
    "    X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "    #Train the model \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Predict the values based on the X test values\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y, state, sml_param):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE, stratify=y)\n",
    "    \n",
    "    #Which solver to fit the model\n",
    "    model_type = \"Logistic Regression\"\n",
    "        \n",
    "    #Set the different types of solvers to compare\n",
    "    solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "    solver = solvers[0]\n",
    "    model = LogisticRegression(solver=solver, max_iter=400, random_state=1)\n",
    "    \n",
    "    #Scale the values\n",
    "    X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    \n",
    "    #Train the model \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Predict the values based on the X test values\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate Scores \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    #df = pd.DataFrame(report).transpose()\n",
    "    df = pd.DataFrame()\n",
    "    df[\"accuracy\"] = accuracy\n",
    "    df[\"recall\"] = recall\n",
    "    df[\"precision\"] = precision\n",
    "    df[\"f1\"] = f1\n",
    "    df[\"sml_param\"] = sml_param\n",
    "    df[\"state\"] = state\n",
    "    df.to_sql(TABLE_RES_LOG, con=engine, if_exists=\"append\")\n",
    "    \n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y, sml_param, state):    \n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE)\n",
    "    \n",
    "    #Test out different models\n",
    "    model = LinearRegression()\n",
    "    #model = RandomForestClassifier()\n",
    "    model_type = \"lr\"\n",
    "    file_name = f\"{model_type}_{sml_param}_{state}.png\"\n",
    "    #Scale the values\n",
    "    X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "        \n",
    "    #Train the model \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Predict the values based on the X test values\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    #Get the score of this model\n",
    "    r2_score_val = r2_score(y_test, y_test_pred)\n",
    "    score_str = f\"r2_score:{r2_score_val}\"\n",
    "    #Plot the data\n",
    "    title = f\"{model_type}-{sml_param}:{score_str}\"\n",
    "    plot_data(y_test, y_train, y_test_pred, y_train_pred, title, file_name)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['state'] = [state]\n",
    "    df['sml_param'] = [sml_param]\n",
    "    df['r2_score'] = [r2_score_val]\n",
    "    df['file_name'] = [file_name]\n",
    "    df.to_sql(TABLE_RES_LR, con=engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(y_test, y_trained, y_pred_test, y_pred_train, title, file_name):\n",
    "    plt.scatter(y_pred_train, y_pred_train - y_trained, c=\"blue\", label=\"Training Data\")\n",
    "    plt.scatter(y_pred_test, y_pred_test - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "    plt.legend()\n",
    "    plt.hlines(y=0, xmin=y_test.min(), xmax=y_test.max())\n",
    "    plt.title(title)\n",
    "    #plt.show()\n",
    "    \n",
    "    file_dir = f\"results/{file_name}\"\n",
    "    plt.savefig(file_dir)\n",
    "    \n",
    "    #Clear the plot\n",
    "    plt.clf()\n",
    "    \n",
    "    #Save the plot data to gcloud\n",
    "    #save_image_to_gcloud_lr(plt, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate tables are the output of this script, drop them to start fresh\n",
    "def drop_res_tables():\n",
    "    if DROP_AGG_TABLE:\n",
    "        sql.execute('DROP TABLE IF EXISTS %s'%TABLE_RES_LR, engine)\n",
    "        sql.execute('DROP TABLE IF EXISTS %s'%TABLE_RES_LOG, engine)\n",
    "        sql.execute('DROP TABLE IF EXISTS %s'%TABLE_RES_SVC, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def query_all(table_name):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    select_sql = f'select * from {table_name}'\n",
    "    df = pd.read_sql_query(select_sql,con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    #select_sql = f'select * from {TABLE_SIX_STATE_DONATIONS} where \"STATE\"=\\'{state.upper()}\\''\n",
    "    select_sql = f'select * from {TABLE_SIX_STATE_DONATIONS} where \"STATE\"=\\'{state.upper()}\\' LIMIT 10000'\n",
    "    donor_df = pd.read_sql_query(select_sql, con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ml():\n",
    "    print(\"agg_ml\")\n",
    "    agg_donors_df = query_all(TABLE_AGG_DONORS)\n",
    "    agg_votes_df = query_all(TABLE_AGG_VOTES)\n",
    "    #Merge on the three fields that make it unique: county, state, and election_year\n",
    "    merged_df = agg_donors_df.merge(agg_votes_df, left_on=['county', 'state', 'election_year'], right_on=['county', 'state', 'election_year'], suffixes=(\"_donors\", \"_votes\"))\n",
    "        \n",
    "    #Run a linear regression analysis on the merged dataset\n",
    "    donation_votes_linear_regression(merged_df)\n",
    "    \n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_ml(committee_df):\n",
    "    #Loop through each state and run separate LR models on each state.\n",
    "    for state in SWING_STATES:\n",
    "        print(f\"state_ml {state}\")\n",
    "        donor_df = donor_state_query(state)\n",
    "        \n",
    "        #Add party column to donor data frame\n",
    "        donor_df = committee_df.merge(donor_df, left_on='CMTE_ID', right_on='CMTE_ID')\n",
    "        \n",
    "        #Print unique ids\n",
    "        unique_aff = donor_df[\"CMTE_PTY_AFFILIATION\"].unique()\n",
    "        print(unique_aff)\n",
    "        \n",
    "        donor_df = merge_cmtid_party(donor_df)\n",
    "\n",
    "        #Run the machine learning models on the donation set\n",
    "        print(f\"Linear Regression on state: {state}\")\n",
    "        donation_linear_regression(donor_df, state)\n",
    "        #Run the machine learning models on the donation set\n",
    "        \n",
    "        print(f\"Logistic Regression on state: {state}\")\n",
    "        donation_logistic_regression(donor_df, state)\n",
    "        \n",
    "        #print(f\"SVC Linear Model on state: {state}\")\n",
    "        #donation_svc_linear_regression(donor_df, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(committee_df):\n",
    "    drop_res_tables()\n",
    "    \n",
    "    print(\"Main\")\n",
    "    #agg_ml()\n",
    "    \n",
    "    state_ml(committee_df)\n",
    "    print(\"End of Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "committee_df = pd.read_sql_query('select * from \"committees\"', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main\n",
      "state_ml AZ\n",
      "['UNK' 'NNE' None 'REP' 'CIT' 'DEM' 'LIB' 'NAT' 'IND' 'DFL' 'OTH']\n",
      "Linear Regression on state: AZ\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: AZ\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "state_ml MI\n",
      "[None 'UNK' 'DEM' 'NNE' 'REP' 'NAT' 'LIB' 'GRE' 'Dem' 'SUB']\n",
      "Linear Regression on state: MI\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: MI\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n",
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "state_ml FL\n",
      "[None 'NNE' 'UNK' 'REP' 'DEM' 'Rep' 'OTH' 'DFL']\n",
      "Linear Regression on state: FL\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: FL\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n",
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "state_ml NC\n",
      "['DEM' 'UNK' None 'NNE' 'REP' 'LIB' 'OTH']\n",
      "Linear Regression on state: NC\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: NC\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n",
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "state_ml PA\n",
      "[None 'UNK' 'NA' 'REP' 'DEM']\n",
      "Linear Regression on state: PA\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: PA\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "state_ml WI\n",
      "[None 'UNK' 'NNE' 'REP' 'DEM' 'PAC' 'DFL' 'NAT']\n",
      "Linear Regression on state: WI\n",
      "Running a Linear Regression Model with y=TRANSACTION_AMT and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION']\n",
      "Logistic Regression on state: WI\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [accuracy, recall, precision, f1, sml_param, state]\n",
      "Index: []\n",
      "End of Main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(committee_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
