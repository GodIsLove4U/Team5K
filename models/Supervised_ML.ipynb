{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from consts import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(CREATE_ENGINE_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['committees', 'candidates', 'education', 'committee_summary_2020', 'six_state_donations', 'donations', 'health_metrics', 'agg_county_votes', 'birth_death_rate', 'postal_codes', 'fec_committee', 'agg_county_donors', 'pres_votes_6t', 'unemployment']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_tuples = state_tuple[0]    \n",
    "    donor_tuples = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_tuples)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_tuples[i]\n",
    "        donor_tuple = donor_tuples[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_tuple)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_votes_linear_regression(df):\n",
    "    #Will run a separate LR model on each of the SML_params\n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"blue_amt\", \"red_amt\", \"blue_num\", \"red_num\"]\n",
    "    #Set all the votes cols of interest\n",
    "    votes_cols = [\"blue_votes\", \"red_votes\", \"other_votes\", \"total_votes\", \"county\", \"state\", \"election_year\", \"PopPct_Urban\", \"Unemployment\", \"PopDen_Urban\", \"PopPct_Rural\", \"PopDen_Rural\"]\n",
    "    #Set all the donors cols of interest\n",
    "    donors_cols = [\"blue_amt\", \"red_amt\", \"other_amt\", \"total_amt\", \"blue_num\", \"red_num\"]\n",
    "    \n",
    "    sml_cols = votes_cols + donors_cols\n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df):\n",
    "    sml_params = [\"TRANSACTION_AMT\"]\n",
    "    sml_cols = [\"CMTE_ID\", \"CITY\", \"STATE\", \"ZIP\", \"EMPLOYER\", \"OCCUPATION\", \"TRANSACTION_AMT\", \"ENTITY_TP\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"CMTE_ID\", \"CITY\", \"STATE\", \"ZIP\", \"EMPLOYER\", \"OCCUPATION\", \"TRANSACTION_AMT\", \"ENTITY_TP\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type):\n",
    "    #Reduce columns to start with\n",
    "    #print(df.head())\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "        \n",
    "        #Run Linear Regression Model on X,y\n",
    "        #Set Y column to just the ML model\n",
    "        y_df = select_columns(df, [sml_param])   \n",
    "        y_df = y_df.fillna(0)\n",
    "        y_df = label_enc(y_df)\n",
    "        y = y_df[sml_param].values\n",
    "    \n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        x_cols = sml_cols.copy()        \n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        X_df = label_enc(X_df)\n",
    "        X = X_df[x_cols].values\n",
    "                \n",
    "        if model_type == 'linear':\n",
    "            print(f\"Running a Linear Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y, sml_param)\n",
    "        elif model_type == 'logistic':\n",
    "            print(f\"Running a Logistics Regression Model with y={sml_param} and x_cols={x_cols}\")\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y, sml_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y, sml_param):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE, stratify=y)\n",
    "    \n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model_type = \"Logistic Regression\"\n",
    "    #Scale the values\n",
    "    #X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "    #Train the model \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Scale the values\n",
    "    #X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    #Predict the values based on the X test values\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y, sml_param):    \n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=SML_TEST_SIZE)\n",
    "    \n",
    "    #Test out different models\n",
    "    model = LinearRegression()\n",
    "    model_type = \"Linear Regression\"\n",
    "    \n",
    "    #Scale the values\n",
    "    X_train_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    \n",
    "    #Train the model \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    #Predict the values based on the X test values\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    #Save X_test_scaled, y_test, y_pred to table\n",
    "    #1. Create plot_data and save the image to a S3 bucket?\n",
    "    #2. Save the output of plot_data(X_test_scaled, y_test, y_pred) county, state, election_year\n",
    "    #\n",
    "    \n",
    "    #Get the score of this model\n",
    "    score_test = model.score(X_test, y_test)\n",
    "    score_test_scale = model.score(X_test_scaled, y_test)\n",
    "    r2_score_val = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    score_str = f\"r2_score:{r2_score_val} score_test:{score_test} score_test_scale:{score_test_scale}\"\n",
    "    #Plot the data\n",
    "    title = f\"{model_type}-{sml_param}:{score_str}\"\n",
    "    plot_data(y_test, y_train, y_test_pred, y_train_pred, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(y_test, y_trained, y_pred_test, y_pred_train, title):\n",
    "    plt.scatter(y_pred_train, y_pred_train - y_trained, c=\"blue\", label=\"Training Data\")\n",
    "    plt.scatter(y_pred_test, y_pred_test - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "    plt.legend()\n",
    "    plt.hlines(y=0, xmin=y_test.min(), xmax=y_test.max())\n",
    "    plt.title(title)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def query_all(table_name):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    select_sql = 'select * from {}'.format(table_name)\n",
    "    df = pd.read_sql_query(select_sql,con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    select_sql = f'select * from {TABLE_SIX_STATE_DONATIONS} where \"STATE\"=\\'{state.upper()}\\''\n",
    "    donor_df = pd.read_sql_query(select_sql, con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ml():\n",
    "    print(\"agg_ml\")\n",
    "    agg_donors_df = query_all(TABLE_AGG_DONORS)\n",
    "    agg_votes_df = query_all(TABLE_AGG_VOTES)\n",
    "    #Merge on the three fields that make it unique: county, state, and election_year\n",
    "    merged_df = agg_donors_df.merge(agg_votes_df, left_on=['county', 'state', 'election_year'], right_on=['county', 'state', 'election_year'], suffixes=(\"_donors\", \"_votes\"))\n",
    "        \n",
    "    #Run a linear regression analysis on the merged dataset\n",
    "    #donation_votes_linear_regression(merged_df)\n",
    "    \n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_ml(committee_df):\n",
    "    print(\"state_ml\")\n",
    "    print(\"Getting FEC committee\")\n",
    "    #Loop through each state and run separate LR models on each state.\n",
    "    for state in SWING_STATES:\n",
    "        donor_df = donor_state_query(state)\n",
    "        \n",
    "        #Add party column to donor data frame\n",
    "        donor_df = committee_df.merge(donor_df, left_on='cmte_id', right_on='CMTE_ID')\n",
    "        donor_df = merge_cmtid_party(donor_df)\n",
    "        \n",
    "        #Run the machine learning models on the donation set\n",
    "        print(f\"Linear Regression on state: {state}\")\n",
    "        #donation_linear_regression(donor_df)\n",
    "        #Run the machine learning models on the donation set\n",
    "        print(f\"Logistic Regression on state: {state}\")\n",
    "        donation_logistic_regression(donor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Main\")\n",
    "    #agg_ml()\n",
    "    \n",
    "    committee_df = pd.read_sql_query('select * from \"fec_committee\"', con=engine)\n",
    "    state_ml(committee_df)\n",
    "    print(\"End of Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main\n",
      "state_ml\n",
      "Getting FEC committee\n",
      "Linear Regression on state: AZ\n",
      "Logistic Regression on state: AZ\n",
      "Running a Logistics Regression Model with y=party and x_cols=['CMTE_ID', 'CITY', 'STATE', 'ZIP', 'EMPLOYER', 'OCCUPATION', 'TRANSACTION_AMT', 'ENTITY_TP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
