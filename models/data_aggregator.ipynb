{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from consts import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure settings for RDS\n",
    "# Defining db info in config var\n",
    "jdbc_url=\"jdbc:postgresql://34.67.52.115/team5k\"\n",
    "config = {'user': 'postgres', \n",
    "          \"password\": \"team5kteam5k\", \n",
    "          \"driver\":\"org.postgresql.Driver\",\n",
    "          \"location\": \"34.67.52.115\",\n",
    "          \"db\": \"team5k\",\n",
    "          \"port\": \"5432\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgres://[user]:[password]@[location]:[port]/[database]\n",
    "create_engine_str = 'postgresql://' + config[\"user\"] + \":\" + config[\"password\"] + \"@\" + config[\"location\"] + \":\" + config[\"port\"] + \"/\" + config[\"db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(create_engine_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'committee_summary_2020', 'agg_county_votes', 'agg_county_donors', 'fec_donor_az', 'health_metrics', 'birth_death_rate', 'postal_codes', 'fec_donor_mi', 'fec_donor_wi', 'fec_committee', 'fec_donor_pa', 'donations', 'pres_votes_6t', 'unemployment', 'fec_donor_nc', 'fec_donor_fl']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_election_yr(i):\n",
    "    return (2000 + i*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(X, y, y_pred):\n",
    "    print(\"X=\" + str(len(X)))\n",
    "    print(X)\n",
    "    print(\"y=\" + str(len(y)))\n",
    "    print(y)\n",
    "    print(\"y_pred\" + str(len(y_pred)))\n",
    "    print(y_pred)\n",
    "    \n",
    "    plt.scatter(X, y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition to take in the votes data frame. Function takes in the votes dataframe with 20 years of data. \n",
    "# This will loop thru every 4 years, runs thru all of the county votes then return it in a list. \n",
    "# This will aggregate everything and return a list in a df\n",
    "\n",
    "def get_votes_intervals(votes_df, state_po):\n",
    "    votes_states_df = votes_df[votes_df['state_po']==state_po]\n",
    "    i = ELECTION_STARTING_YR\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "    while (i <= ELECTION_ENDING_YR):\n",
    "        votes_states_interval_df = votes_states_df[votes_states_df['year']==i]    \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += ELECTION_INTERVAL\n",
    "    \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes thru each county (string), to pull the election date and calculate votes in the county that are democrat (blue), republic (red) and other. \n",
    "\n",
    "def vote_distribution(county, election_df, state, i):        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==MAJOR_PARTIES[0]]\n",
    "    county_red_df = county_df[county_df['party']==MAJOR_PARTIES[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_votes = 0\n",
    "    blue_votes = pd.to_numeric(county_blue_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    red_votes = pd.to_numeric(county_red_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    unique_parties = county_df['party'].unique()\n",
    "    for party in unique_parties:\n",
    "        #Get a sum of all non major parties for other category\n",
    "        if party not in MAJOR_PARTIES:\n",
    "            party_df = county_df[county_df['party']==party]\n",
    "            other_votes += pd.to_numeric(party_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total votes it the sum of blue + red + other\n",
    "    total_votes = blue_votes + red_votes + other_votes\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_votes / total_votes)\n",
    "    percent_red = (red_votes / total_votes)\n",
    "    percent_other = (other_votes / total_votes)\n",
    "    \n",
    "    election_year = calculate_election_yr(i)\n",
    "    county_tuple = (\n",
    "        blue_votes,\n",
    "        red_votes,\n",
    "        other_votes,\n",
    "        total_votes,\n",
    "        percent_blue,\n",
    "        percent_red,\n",
    "        percent_other,\n",
    "        county,\n",
    "        state,\n",
    "        election_year\n",
    "    )\n",
    "    return county_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donor_distribution(election_df, county, state, i):    \n",
    "    county = county.strip()\n",
    "        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==MAJOR_PARTIES[0]]\n",
    "    county_red_df = county_df[county_df['party']==MAJOR_PARTIES[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_amt = 0\n",
    "    blue_amt = pd.to_numeric(county_blue_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    red_amt = pd.to_numeric(county_red_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    unique_parties = county_df['party'].unique()\n",
    "    for party in unique_parties:\n",
    "        #Get a sum of all non major parties for other category\n",
    "        if party not in MAJOR_PARTIES:\n",
    "            party_df = county_df[county_df['party']==party]\n",
    "            other_amt += pd.to_numeric(party_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total transaction amount it the sum of blue + red + other\n",
    "    total_amt = blue_amt + red_amt + other_amt\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_amt / total_amt)\n",
    "    percent_red = (red_amt / total_amt)\n",
    "    percent_other = (other_amt / total_amt)\n",
    "    \n",
    "    election_year = calculate_election_yr(i)\n",
    "    donor_tuple = (\n",
    "        blue_amt,\n",
    "        red_amt,\n",
    "        other_amt,\n",
    "        total_amt,\n",
    "        percent_blue,\n",
    "        percent_red,\n",
    "        percent_other,\n",
    "        county,\n",
    "        state,\n",
    "        election_year\n",
    "    )\n",
    "    return donor_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run every election year in the loop, get election df, look for the vote distribution\n",
    "# Will be run on a single state and will return a dictionary tha tcountains every county in the state as a key. \n",
    "# The value (number of votes) is a dictionary of values.\n",
    "\n",
    "def county_vote_distribution(four_yr_dfs, state):\n",
    "    #Loop through each election DF\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        election_df = four_yr_dfs[i]\n",
    "        unique_counties = election_df[\"county\"].unique()\n",
    "        print(f\"Running county election year: {calculate_election_yr(i)} num countines: {len(unique_counties)}\")\n",
    "        \n",
    "        #Loop through each unique county\n",
    "        for county in unique_counties:\n",
    "            print(f\"Running county: {county}\")\n",
    "            #Get the percent of the vote distribution for that county\n",
    "            county_tuple = vote_distribution(county, election_df, state, i)            \n",
    "            county_votes_df = pd.DataFrame([county_tuple], columns=VOTES_COLS)\n",
    "            #print(\"county_votes_df\")\n",
    "            #print(county_votes_df.size)\n",
    "            #print(county_votes_df.head())\n",
    "            #Write the vote tallies per county to DB\n",
    "            county_votes_df.to_sql(TABLE_AGG_VOTES, con=engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nACE\\tAce Party\\t\\nAKI\\tAlaskan Independence Party\\t\\nAIC\\tAmerican Independent Conservative\\t\\nAIP\\tAmerican Independent Party\\t\\nAMP\\tAmerican Party\\t\\nAPF\\tAmerican People's Freedom Party\\t\\nAE\\tAmericans Elect\\t\\nCIT\\tCitizens' Party\\t\\nCMD\\tCommandments Party\\t\\nCMP\\tCommonwealth Party of the U.S.\\t\\nCOM\\tCommunist Party\\t\\nCNC\\tConcerned Citizens Party Of Connecticut\\t\\nCRV\\tConservative Party\\t\\nCON\\tConstitution Party\\t\\nCST\\tConstitutional\\t\\nCOU\\tCountry\\t\\nDCG\\tD.C. Statehood Green Party\\t\\nDNL\\tDemocratic -Nonpartisan League\\t\\nDEM\\tDemocratic Party\\t\\nD/C\\tDemocratic/Conservative\\t\\nDFL\\tDemocratic-Farmer-Labor\\t\\nDGR\\tDesert Green Party\\t\\nFED\\tFederalist\\t\\nFLP\\tFreedom Labor Party\\t\\nFRE\\tFreedom Party\\t\\nGWP\\tGeorge Wallace Party\\t\\nGRT\\tGrassroots\\t\\nGRE\\tGreen Party\\t\\nGR\\tGreen-Rainbow\\t\\nHRP\\tHuman Rights Party\\t\\nIDP\\tIndependence Party\\t\\nIND\\tIndependent\\t\\nIAP\\tIndependent American Party\\t\\nICD\\tIndependent Conservative Democratic\\t\\nIGR\\tIndependent Green\\t\\nIP\\tIndependent Party\\t\\nIDE\\tIndependent Party of Delaware\\t\\nIGD\\tIndustrial Government Party\\t\\nJCN\\tJewish/Christian National\\t\\nJUS\\tJustice Party\\t\\nLRU\\tLa Raza Unida\\tAlso see RUP\\nLBR\\tLabor Party\\tAlso see LAB\\nLFT\\tLess Federal Taxes\\t\\nLBL\\tLiberal Party\\t\\nLIB\\tLibertarian Party\\t\\nLBU\\tLiberty Union Party\\t\\nMTP\\tMountain Party\\t\\nNDP\\tNational Democratic Party\\t\\nNLP\\tNatural Law Party\\t\\nNA\\tNew Alliance\\t\\nNJC\\tNew Jersey Conservative Party\\t\\nNPP\\tNew Progressive Party\\t\\nNPA\\tNo Party Affiliation\\t\\nNOP\\tNo Party Preference\\tCommonly used in CA & WA\\nNNE\\tNone\\t\\nN\\tNonpartisan\\t\\nNON\\tNon-Party\\t\\nOE\\tOne Earth Party\\t\\nOTH\\tOther\\t\\nPG\\tPacific Green\\t\\nPSL\\tParty for Socialism and Liberation\\t\\nPAF\\tPeace And Freedom\\tAlso see PFP\\nPFP\\tPeace And Freedom Party\\tAlso see PAF\\nPFD\\tPeace Freedom Party\\t\\nPOP\\tPeople Over Politics\\t\\nPPY\\tPeople's Party\\t\\nPCH\\tPersonal Choice Party\\t\\nPPD\\tPopular Democratic Party\\t\\nPRO\\tProgressive Party\\t\\nNAP\\tProhibition Party\\t\\nPRI\\tPuerto Rican Independence Party\\t\\nRUP\\tRaza Unida Party\\tAlso see LRU\\nREF\\tReform Party\\t\\nREP\\tRepublican Party\\t\\nRES\\tResource Party\\t\\nRTL\\tRight To Life\\t\\nSEP\\tSocialist Equality Party\\t\\nSLP\\tSocialist Labor Party\\t\\nSUS\\tSocialist Party\\t\\nSOC\\tSocialist Party U.S.A.\\t\\nSWP\\tSocialist Workers Party\\t\\nTX\\tTaxpayers\\t\\nTWR\\tTaxpayers Without Representation\\t\\nTEA\\tTea Party\\t\\nTHD\\tTheo-Democratic\\t\\nLAB\\tU.S. Labor Party\\tAlso see LBR\\nUSP\\tU.S. People's Party\\t\\nUST\\tU.S. Taxpayers Party\\t\\nUN\\tUnaffiliated\\t\\nUC\\tUnited Citizen\\t\\nUNI\\tUnited Party\\t\\nUNK\\tUnknown\\t\\nVET\\tVeterans Party\\t\\nWTP\\tWe the People\\t\\nW\\tWrite-In\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ACE\tAce Party\t\n",
    "AKI\tAlaskan Independence Party\t\n",
    "AIC\tAmerican Independent Conservative\t\n",
    "AIP\tAmerican Independent Party\t\n",
    "AMP\tAmerican Party\t\n",
    "APF\tAmerican People's Freedom Party\t\n",
    "AE\tAmericans Elect\t\n",
    "CIT\tCitizens' Party\t\n",
    "CMD\tCommandments Party\t\n",
    "CMP\tCommonwealth Party of the U.S.\t\n",
    "COM\tCommunist Party\t\n",
    "CNC\tConcerned Citizens Party Of Connecticut\t\n",
    "CRV\tConservative Party\t\n",
    "CON\tConstitution Party\t\n",
    "CST\tConstitutional\t\n",
    "COU\tCountry\t\n",
    "DCG\tD.C. Statehood Green Party\t\n",
    "DNL\tDemocratic -Nonpartisan League\t\n",
    "DEM\tDemocratic Party\t\n",
    "D/C\tDemocratic/Conservative\t\n",
    "DFL\tDemocratic-Farmer-Labor\t\n",
    "DGR\tDesert Green Party\t\n",
    "FED\tFederalist\t\n",
    "FLP\tFreedom Labor Party\t\n",
    "FRE\tFreedom Party\t\n",
    "GWP\tGeorge Wallace Party\t\n",
    "GRT\tGrassroots\t\n",
    "GRE\tGreen Party\t\n",
    "GR\tGreen-Rainbow\t\n",
    "HRP\tHuman Rights Party\t\n",
    "IDP\tIndependence Party\t\n",
    "IND\tIndependent\t\n",
    "IAP\tIndependent American Party\t\n",
    "ICD\tIndependent Conservative Democratic\t\n",
    "IGR\tIndependent Green\t\n",
    "IP\tIndependent Party\t\n",
    "IDE\tIndependent Party of Delaware\t\n",
    "IGD\tIndustrial Government Party\t\n",
    "JCN\tJewish/Christian National\t\n",
    "JUS\tJustice Party\t\n",
    "LRU\tLa Raza Unida\tAlso see RUP\n",
    "LBR\tLabor Party\tAlso see LAB\n",
    "LFT\tLess Federal Taxes\t\n",
    "LBL\tLiberal Party\t\n",
    "LIB\tLibertarian Party\t\n",
    "LBU\tLiberty Union Party\t\n",
    "MTP\tMountain Party\t\n",
    "NDP\tNational Democratic Party\t\n",
    "NLP\tNatural Law Party\t\n",
    "NA\tNew Alliance\t\n",
    "NJC\tNew Jersey Conservative Party\t\n",
    "NPP\tNew Progressive Party\t\n",
    "NPA\tNo Party Affiliation\t\n",
    "NOP\tNo Party Preference\tCommonly used in CA & WA\n",
    "NNE\tNone\t\n",
    "N\tNonpartisan\t\n",
    "NON\tNon-Party\t\n",
    "OE\tOne Earth Party\t\n",
    "OTH\tOther\t\n",
    "PG\tPacific Green\t\n",
    "PSL\tParty for Socialism and Liberation\t\n",
    "PAF\tPeace And Freedom\tAlso see PFP\n",
    "PFP\tPeace And Freedom Party\tAlso see PAF\n",
    "PFD\tPeace Freedom Party\t\n",
    "POP\tPeople Over Politics\t\n",
    "PPY\tPeople's Party\t\n",
    "PCH\tPersonal Choice Party\t\n",
    "PPD\tPopular Democratic Party\t\n",
    "PRO\tProgressive Party\t\n",
    "NAP\tProhibition Party\t\n",
    "PRI\tPuerto Rican Independence Party\t\n",
    "RUP\tRaza Unida Party\tAlso see LRU\n",
    "REF\tReform Party\t\n",
    "REP\tRepublican Party\t\n",
    "RES\tResource Party\t\n",
    "RTL\tRight To Life\t\n",
    "SEP\tSocialist Equality Party\t\n",
    "SLP\tSocialist Labor Party\t\n",
    "SUS\tSocialist Party\t\n",
    "SOC\tSocialist Party U.S.A.\t\n",
    "SWP\tSocialist Workers Party\t\n",
    "TX\tTaxpayers\t\n",
    "TWR\tTaxpayers Without Representation\t\n",
    "TEA\tTea Party\t\n",
    "THD\tTheo-Democratic\t\n",
    "LAB\tU.S. Labor Party\tAlso see LBR\n",
    "USP\tU.S. People's Party\t\n",
    "UST\tU.S. Taxpayers Party\t\n",
    "UN\tUnaffiliated\t\n",
    "UC\tUnited Citizen\t\n",
    "UNI\tUnited Party\t\n",
    "UNK\tUnknown\t\n",
    "VET\tVeterans Party\t\n",
    "WTP\tWe the People\t\n",
    "W\tWrite-In\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_zip_county(unique_zips, state_zips):\n",
    "    county_dict = {}\n",
    "    unique_counties = {}\n",
    "    for zipcode in unique_zips:\n",
    "        #Filter out on the zip code from the state_zips DF\n",
    "        county_zip = state_zips[state_zips[\"zip\"] == zipcode]\n",
    "        #Get the county name from the DF and convert it to lower\n",
    "        county_name = county_zip[\"county\"].to_string(index=False).strip().lower()\n",
    "        #Filter out the county string within\n",
    "        county_name = county_name.replace(\" county\", \"\").capitalize()\n",
    "        \n",
    "        county_dict[zipcode] = county_name\n",
    "        if county_name not in unique_counties:\n",
    "            unique_counties[county_name] = True\n",
    "            \n",
    "    return (county_dict, unique_counties.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df, column_names):\n",
    "    new_frame = df.loc[:, column_names]\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    # Generate our categorical variable list\n",
    "    cat_vars = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[cat_vars]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(cat_vars)\n",
    "    \n",
    "    return encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_enc(df):\n",
    "    # Create encoder\n",
    "    le = LabelEncoder()\n",
    "    # Encode first DataFrame 1 (where all values are floats)\n",
    "    df = df.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y, x_cols):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25)\n",
    "    model = LinearRegression()\n",
    "    #Train the model \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #Scale the values\n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    #Predict the values based on the X test values\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "    print(\"Prediction!!\")\n",
    "    print(\"Confusion Matrix!!\")\n",
    "    #y_test = y_test[\"transaction_amt\"].tolist()\n",
    "    \n",
    "    #Cast to int for the confusion matrix\n",
    "    y_test = [int(i) for i in y_test]\n",
    "    y_pred = [int(i) for i in y_pred]\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    print(\"Classificaiton Report!!\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25, stratify=y)\n",
    "    \n",
    "    classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type):\n",
    "    #Reduce columns to start with\n",
    "    #print(df.head())\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "        \n",
    "        #Run Linear Regression Model on X,y\n",
    "        #Set Y column to just the ML model\n",
    "        y_df = select_columns(df, [sml_param])   \n",
    "        y_df = y_df.fillna(0)\n",
    "        y_df = label_enc(y_df)\n",
    "        y = y_df[sml_param].values\n",
    "    \n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        x_cols = sml_cols\n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        X_df = label_enc(X_df)\n",
    "        X = X_df[x_cols].values\n",
    "        \n",
    "        if model_type == 'linear':\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y, x_cols)\n",
    "        elif model_type == 'logistic':\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column party to the DF that maps the committee party abbreviation to a major party\n",
    "def merge_cmtid_party(donor_df):        \n",
    "    #Get the major party strings to map to \n",
    "    party_repub = MAJOR_PARTIES[1]\n",
    "    party_democrat = MAJOR_PARTIES[0]\n",
    "    party_other = \"other\"\n",
    "    \n",
    "    #Map the affiliation code to the party affiliation\n",
    "    cmte_party_map = {\n",
    "        \"REP\": party_repub,\n",
    "        \"TEA\": party_repub,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DEM\": party_democrat,\n",
    "        \"D/C\": party_democrat,\n",
    "        \"DFL\": party_democrat,\n",
    "        \"THD\": party_democrat,\n",
    "        \"PPD\": party_democrat,\n",
    "        \"UNK\": party_other\n",
    "    }\n",
    "    \n",
    "    donor_df[\"party\"] = donor_df[\"cmte_pty_affiliation\"].map(cmte_party_map)\n",
    "    \n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: expecting '}' (<ipython-input-23-f82105399ffa>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-f82105399ffa>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print(f\"Running donor distribution election yr: {calculate_election_yr(i)} num countines: {len(unique_counties)\")\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: expecting '}'\n"
     ]
    }
   ],
   "source": [
    "#Loop through each of the election year DFs and \n",
    "def donation_county_cycle_distribution(four_yr_dfs, state_zips, committee_df, state):\n",
    "    #Loop through each election year DF\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        election_df = four_yr_dfs[i]\n",
    "        #Without zipcode can't do a county lookup, so drop all null values\n",
    "        election_df.dropna(subset=[\"zip\"], inplace=True)\n",
    "        #Get the unique values of zip code in the election DF\n",
    "        unique_zips = election_df[\"zip\"].unique()\n",
    "        #Createa a map of zip to county, and a list of all unique counties in that state\n",
    "        (zip_county_map, unique_counties) = map_zip_county(unique_zips, state_zips)\n",
    "        #Map the zipcode to the county name per the map function\n",
    "        election_df[\"county\"] = election_df[\"zip\"].map(zip_county_map)\n",
    "        \n",
    "        print(f\"Running donor distribution election yr: {calculate_election_yr(i)} num countines: {len(unique_counties)}\")\n",
    "\n",
    "        #Loop through each unique county\n",
    "        for county in unique_counties:\n",
    "            print(f\"Running county: {county}\")\n",
    "            #Get the donor distribution for that county, state, election year as a tuple\n",
    "            donor_tuple = donor_distribution(election_df, county, state, i)\n",
    "            #Create a DF to store the county donor info\n",
    "            donor_df = pd.DataFrame([donor_tuple], columns = DONOR_COLS)  \n",
    "            #Write the donation amounts to the DB\n",
    "            donor_df.to_sql(TABLE_AGG_DONORS, con=engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dt(donor_date_str):\n",
    "    #01/01/1996 - 12/31/1999\n",
    "    donor_date = datetime.strptime(donor_date_str, '%Y-%m-%d')\n",
    "    return donor_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_date_str(donor_date_str):\n",
    "    donor_date = str_dt(donor_date_str)\n",
    "    donor_year = donor_date.year\n",
    "    return donor_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donors_intervals(donor_df, state):\n",
    "    donors_states_df = donor_df[donor_df['state']==state.lower()]\n",
    "    \n",
    "    i = ELECTION_STARTING_YR\n",
    "    prev_year = ELECTION_STARTING_YR - interval\n",
    "    ending_yr = 2020\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "        \n",
    "    while (i <= ELECTION_ENDING_YR):\n",
    "        votes_states_interval_df = donors_states_df[(donors_states_df['transaction_dt']>datetime.date(prev_year,1,1)) & (donors_states_df['transaction_dt']<datetime.date(i,3,1))]          \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += ELECTION_INTERVAL\n",
    "        prev_year += ELECTION_INTERVAL\n",
    "        \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state, engine):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    donor_table_name = '\"fec_donor_{}\"'.format(state.lower())    \n",
    "    donor_select_sql = 'select * from {}'.format(donor_table_name)\n",
    "    donor_df = pd.read_sql_query(donor_select_sql,con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the Voter data\n",
    "def votes_linear_regression(votes_df):    \n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\"]\n",
    "    sml_cols = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\", \"state\", \"county\"]\n",
    "    \n",
    "    run_linear_regression_params(votes_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df):\n",
    "    sml_params = [\"transaction_amt\", \"employer\", \"occupation\"]\n",
    "    #sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate tables are the output of this script, drop them to start fresh\n",
    "def drop_agg_tables():\n",
    "    sql.execute('DROP TABLE IF EXISTS %s'%TABLE_AGG_DONORS, engine)\n",
    "    sql.execute('DROP TABLE IF EXISTS %s'%TABLE_AGG_VOTES, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop of the program\n",
    "def main():\n",
    "    #Read the various tables into DFs\n",
    "    health_df = pd.read_sql_query('select * from \"health_metrics\"',con=engine)\n",
    "    committee_df = pd.read_sql_query('select * from \"fec_committee\"',con=engine)\n",
    "    votes_df = pd.read_sql_query('select * from \"pres_votes_6t\"',con=engine)\n",
    "    zips_df = pd.read_sql_query('select * from \"postal_codes\"',con=engine)\n",
    "    \n",
    "    #Lowercase the column\n",
    "    committee_df['cmte_id'] = committee_df['cmte_id'].str.lower()\n",
    "    \n",
    "    #Drop the aggregate tables to do fresh data analysis\n",
    "    drop_agg_tables()\n",
    "\n",
    "    #Loop through each state\n",
    "    for state in SWING_STATES:\n",
    "        print(\"State:\" + state)\n",
    "        print(\"Aggregating Vote and Donation records...\")\n",
    "        #Get the votes related to that state\n",
    "        votes_intervals_df = get_votes_intervals(votes_df, state)\n",
    "\n",
    "        #Get the distribution of Red, Blue, and Other votes in a list of dict per election yr e.g. 2000 + 4n\n",
    "        county_vote_distribution(votes_intervals_df, state)\n",
    "        \n",
    "        #DF that has all donation records for a state\n",
    "        donor_df_orig = donor_state_query(state, engine)\n",
    "        \n",
    "        #Add party column to donor data frame\n",
    "        donor_df = committee_df.merge(donor_df_orig, left_on='cmte_id', right_on='cmt_id')\n",
    "        donor_df = merge_cmtid_party(donor_df)\n",
    "        \n",
    "        #Get a list of DFs per election year per state\n",
    "        donors_intervals_df = get_donors_intervals(donor_df, state)\n",
    "        #Filter out the zips DF by the state\n",
    "        state_zips = zips_df[zips_df[\"state\"] == state]\n",
    "                \n",
    "        #Get list of tuples \n",
    "        donation_county_cycle_distribution(donors_intervals_df, state_zips, committee_df, state)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Swing States Aggregation Done!\")\n",
    "    #Run the machine learning models on the donation set\n",
    "    #donation_linear_regression(donor_df)\n",
    "    \n",
    "    #TODO Once we have full dataset, then enable logistic regression\n",
    "    #donation_logistic_regression(donor_df)\n",
    "        \n",
    "    #TODO enable the neural networking code\n",
    "    #state_nn(state_tuple)\n",
    "    \n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)\n",
    "    \n",
    "    #TODO: Run Linear regression on the votes\n",
    "    #votes_linear_regression(votes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_votes_dict(votes_dict, county_votes, donor_dict):\n",
    "    votes_dict[\"blue_votes\"] = county_votes[\"blue_votes\"]\n",
    "    votes_dict[\"red_votes\"] = county_votes[\"red_votes\"]\n",
    "    votes_dict[\"other_votes\"] = county_votes[\"other_votes\"]\n",
    "    votes_dict[\"state\"] = county_votes[\"state\"]\n",
    "    votes_dict[\"county\"] = county_votes[\"county\"]\n",
    "\n",
    "    for donor_c in donor_dict:\n",
    "        if c == donor_c:\n",
    "            county_donors = donor_dict[donor_c]\n",
    "            votes_dict[\"blue_amt\"] = county_donors[\"blue_amt\"]\n",
    "            votes_dict[\"red_amt\"] = county_donors[\"red_amt\"]\n",
    "            votes_dict[\"other_amt\"] = county_donors[\"other_amt\"]\n",
    "            break\n",
    "\n",
    "    #TODO set the unemployment data\n",
    "    \"\"\"  \n",
    "    unemployment = unemployment_df[(unemployment_df[\"County\"] == c) & (unemployment_df[\"Stabr\"] == state)]\n",
    "    unemployment_col = \"Unemployment_rate_\" + str(election_yr)\n",
    "    votes_dict[\"POPPCT_URBAN\"] = pd.to_numeric(unemployment[\"POPPCT_URBAN\"].values[0])\n",
    "    votes_dict[unemployment_col] = unemployment[unemployment_col].values[0]\n",
    "    votes_dict[\"POPDEN_URBAN\"] = unemployment[\"POPDEN_URBAN\"].values[0]\n",
    "    votes_dict[\"POPPCT_RURAL\"] = unemployment[\"POPPCT_RURAL\"].values[0]\n",
    "    votes_dict[\"POPDEN_RURAL\"] = unemployment[\"POPDEN_RURAL\"].values[0]\n",
    "    \"\"\" \n",
    "    return votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_tuples = state_tuple[0]    \n",
    "    donor_tuples = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_tuples)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_tuples[i]\n",
    "        donor_tuple = donor_tuples[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_tuple)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network model on the counties of votes and donors\n",
    "def run_nn_print(counties_votes_dict, donor_dict):\n",
    "    print(\"run_nn_print\")\n",
    "    print(counties_votes_dict)\n",
    "    print(donor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network model on the counties of votes and donors\n",
    "def run_nn(counties_votes_dict, donor_dict):\n",
    "    #Neural Networking Code\n",
    "    nn_df = pd.DataFrame(counties_votes_dict)\n",
    "    \n",
    "    # Generate our categorical variable list\n",
    "    votes_mi_cat = nn_df.dtypes[nn_df.dtypes == \"object\"].index.tolist()\n",
    "    \n",
    "    # Check the number of unique values in each column\n",
    "    nn_df[votes_mi_cat].nunique()\n",
    "    \n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(nn_df[votes_mi_cat]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(votes_mi_cat)\n",
    "    encode_df.head()\n",
    "    \n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Define the model - deep neural net\n",
    "    number_input_features = len(X_train[0])\n",
    "    hidden_nodes_layer1 =  8\n",
    "    hidden_nodes_layer2 = 5\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(\n",
    "        tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    "    )\n",
    "\n",
    "    # Second hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Check the structure of the model\n",
    "    nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given each county vote distribiton and donor distribution, run neural networks.\n",
    "def state_nn(state_tuple):\n",
    "    counties_tuples = state_tuple[0]\n",
    "    donor_tuples = state_tuple[1]\n",
    "    \n",
    "    for i in range(0, len(counties_tuples)):\n",
    "        counties_votes_dict = counties_tuples[i]\n",
    "        donor_tuple = donor_tuples[i]\n",
    "        #TODO enable the nn function, requires a DF\n",
    "        run_nn(counties_tuples, donor_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the main loop\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
