{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure settings for RDS\n",
    "# Defining db info in config var\n",
    "jdbc_url=\"jdbc:postgresql://34.67.52.115/team5k\"\n",
    "config = {'user': 'postgres', \n",
    "          \"password\": \"team5kteam5k\", \n",
    "          \"driver\":\"org.postgresql.Driver\",\n",
    "          \"location\": \"34.67.52.115\",\n",
    "          \"db\": \"team5k\",\n",
    "          \"port\": \"5432\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgres://[user]:[password]@[location]:[port]/[database]\n",
    "create_engine_str = 'postgresql://' + config[\"user\"] + \":\" + config[\"password\"] + \"@\" + config[\"location\"] + \":\" + config[\"port\"] + \"/\" + config[\"db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(create_engine_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'committee_summary_2020', 'fec_donor_az', 'health_metrics', 'birth_death_rate', 'postal_codes', 'fec_donor_mi', 'fec_donor_wi', 'fec_committee', 'fec_donor_pa', 'pres_votes_6t', 'unemployment', 'fec_donor_nc', 'fec_donor_fl']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(X, y, y_pred):\n",
    "    print(\"X=\" + str(len(X)))\n",
    "    print(X)\n",
    "    print(\"y=\" + str(len(y)))\n",
    "    print(y)\n",
    "    \n",
    "    plt.scatter(X[0], y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition to take in the votes data frame. Function takes in the votes dataframe with 20 years of data. \n",
    "# This will loop thru every 4 years, runs thru all of the county votes then return it in a list. \n",
    "# This will aggregate everything and return a list in a df\n",
    "\n",
    "def get_votes_intervals(votes_df, state_po):\n",
    "    votes_states_df = votes_df[votes_df['state_po']==state_po]\n",
    "    starting_yr = 2000\n",
    "    ending_yr = 2020\n",
    "    interval = 4\n",
    "    i = starting_yr\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "    while (i <= ending_yr):\n",
    "        votes_states_interval_df = votes_states_df[votes_states_df['year']==i]    \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += interval\n",
    "    \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes thru each county (string), to pull the election date and calculate votes in the county that are democrat (blue), republic (red) and other. \n",
    "\n",
    "def vote_distribution(county, election_df, state):\n",
    "    major_parties = [\"democrat\", \"republican\"]\n",
    "        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==major_parties[0]]\n",
    "    county_red_df = county_df[county_df['party']==major_parties[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_votes = 0\n",
    "    blue_votes = pd.to_numeric(county_blue_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    red_votes = pd.to_numeric(county_red_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    unique_parties = county_df['party'].unique()\n",
    "    for party in unique_parties:\n",
    "        #Get a sum of all non major parties for other category\n",
    "        if party not in major_parties:\n",
    "            party_df = county_df[county_df['party']==party]\n",
    "            other_votes += pd.to_numeric(party_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total votes it the sum of blue + red + other\n",
    "    total_votes = blue_votes + red_votes + other_votes\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_votes / total_votes)\n",
    "    percent_red = (red_votes / total_votes)\n",
    "    percent_other = (other_votes / total_votes)\n",
    "            \n",
    "    percent_dict = {\n",
    "        \"blue_votes\": blue_votes,\n",
    "        \"red_votes\": red_votes,\n",
    "        \"other_votes\": other_votes,\n",
    "        \"total_votes\": total_votes,\n",
    "        \"percent_blue\": percent_blue,\n",
    "        \"percent_red\": percent_red,\n",
    "        \"percent_other\": percent_other,\n",
    "        \"county\": county,\n",
    "        \"state\": state\n",
    "    }\n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donor_distribution(county, election_df):    \n",
    "    county = county.strip()\n",
    "    #Total sum of donations per party per county\n",
    "    major_parties = [\"democrat\", \"republican\"]\n",
    "        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==major_parties[0]]\n",
    "    county_red_df = county_df[county_df['party']==major_parties[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_amt = 0\n",
    "    blue_amt = pd.to_numeric(county_blue_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    red_amt = pd.to_numeric(county_red_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    unique_parties = county_df['party'].unique()\n",
    "    for party in unique_parties:\n",
    "        #Get a sum of all non major parties for other category\n",
    "        if party not in major_parties:\n",
    "            party_df = county_df[county_df['party']==party]\n",
    "            other_amt += pd.to_numeric(party_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total transaction amount it the sum of blue + red + other\n",
    "    total_amt = blue_amt + red_amt + other_amt\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_amt / total_amt)\n",
    "    percent_red = (red_amt / total_amt)\n",
    "    percent_other = (other_amt / total_amt)\n",
    "            \n",
    "    percent_dict = {\n",
    "        \"blue_amt\": blue_amt,\n",
    "        \"red_amt\": red_amt,\n",
    "        \"other_amt\": other_amt,\n",
    "        \"total_amt\": total_amt,\n",
    "        \"percent_blue\": percent_blue,\n",
    "        \"percent_red\": percent_red,\n",
    "        \"percent_other\": percent_other\n",
    "    }\n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run every election year in the loop, get election df, look for the vote distribution\n",
    "# Will be run on a single state and will return a dictionary tha tcountains every county in the state as a key. \n",
    "# The value (number of votes) is a dictionary of values.\n",
    "\n",
    "def county_vote_distribution(four_yr_dfs, state):\n",
    "    #Organize by county\n",
    "    county_dicts = []\n",
    "    #Loop through each election DF\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        county_dict = {}\n",
    "        election_df = four_yr_dfs[i]\n",
    "        unique_counties = election_df[\"county\"].unique()\n",
    "        #Loop through each unique county\n",
    "        for county in unique_counties:\n",
    "            #Get the percent of the vote distribution for that county\n",
    "            percent_dict = vote_distribution(county, election_df, state)\n",
    "            county_dict[county] = percent_dict\n",
    "        county_dicts.append(county_dict)\n",
    "    return county_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nACE\\tAce Party\\t\\nAKI\\tAlaskan Independence Party\\t\\nAIC\\tAmerican Independent Conservative\\t\\nAIP\\tAmerican Independent Party\\t\\nAMP\\tAmerican Party\\t\\nAPF\\tAmerican People's Freedom Party\\t\\nAE\\tAmericans Elect\\t\\nCIT\\tCitizens' Party\\t\\nCMD\\tCommandments Party\\t\\nCMP\\tCommonwealth Party of the U.S.\\t\\nCOM\\tCommunist Party\\t\\nCNC\\tConcerned Citizens Party Of Connecticut\\t\\nCRV\\tConservative Party\\t\\nCON\\tConstitution Party\\t\\nCST\\tConstitutional\\t\\nCOU\\tCountry\\t\\nDCG\\tD.C. Statehood Green Party\\t\\nDNL\\tDemocratic -Nonpartisan League\\t\\nDEM\\tDemocratic Party\\t\\nD/C\\tDemocratic/Conservative\\t\\nDFL\\tDemocratic-Farmer-Labor\\t\\nDGR\\tDesert Green Party\\t\\nFED\\tFederalist\\t\\nFLP\\tFreedom Labor Party\\t\\nFRE\\tFreedom Party\\t\\nGWP\\tGeorge Wallace Party\\t\\nGRT\\tGrassroots\\t\\nGRE\\tGreen Party\\t\\nGR\\tGreen-Rainbow\\t\\nHRP\\tHuman Rights Party\\t\\nIDP\\tIndependence Party\\t\\nIND\\tIndependent\\t\\nIAP\\tIndependent American Party\\t\\nICD\\tIndependent Conservative Democratic\\t\\nIGR\\tIndependent Green\\t\\nIP\\tIndependent Party\\t\\nIDE\\tIndependent Party of Delaware\\t\\nIGD\\tIndustrial Government Party\\t\\nJCN\\tJewish/Christian National\\t\\nJUS\\tJustice Party\\t\\nLRU\\tLa Raza Unida\\tAlso see RUP\\nLBR\\tLabor Party\\tAlso see LAB\\nLFT\\tLess Federal Taxes\\t\\nLBL\\tLiberal Party\\t\\nLIB\\tLibertarian Party\\t\\nLBU\\tLiberty Union Party\\t\\nMTP\\tMountain Party\\t\\nNDP\\tNational Democratic Party\\t\\nNLP\\tNatural Law Party\\t\\nNA\\tNew Alliance\\t\\nNJC\\tNew Jersey Conservative Party\\t\\nNPP\\tNew Progressive Party\\t\\nNPA\\tNo Party Affiliation\\t\\nNOP\\tNo Party Preference\\tCommonly used in CA & WA\\nNNE\\tNone\\t\\nN\\tNonpartisan\\t\\nNON\\tNon-Party\\t\\nOE\\tOne Earth Party\\t\\nOTH\\tOther\\t\\nPG\\tPacific Green\\t\\nPSL\\tParty for Socialism and Liberation\\t\\nPAF\\tPeace And Freedom\\tAlso see PFP\\nPFP\\tPeace And Freedom Party\\tAlso see PAF\\nPFD\\tPeace Freedom Party\\t\\nPOP\\tPeople Over Politics\\t\\nPPY\\tPeople's Party\\t\\nPCH\\tPersonal Choice Party\\t\\nPPD\\tPopular Democratic Party\\t\\nPRO\\tProgressive Party\\t\\nNAP\\tProhibition Party\\t\\nPRI\\tPuerto Rican Independence Party\\t\\nRUP\\tRaza Unida Party\\tAlso see LRU\\nREF\\tReform Party\\t\\nREP\\tRepublican Party\\t\\nRES\\tResource Party\\t\\nRTL\\tRight To Life\\t\\nSEP\\tSocialist Equality Party\\t\\nSLP\\tSocialist Labor Party\\t\\nSUS\\tSocialist Party\\t\\nSOC\\tSocialist Party U.S.A.\\t\\nSWP\\tSocialist Workers Party\\t\\nTX\\tTaxpayers\\t\\nTWR\\tTaxpayers Without Representation\\t\\nTEA\\tTea Party\\t\\nTHD\\tTheo-Democratic\\t\\nLAB\\tU.S. Labor Party\\tAlso see LBR\\nUSP\\tU.S. People's Party\\t\\nUST\\tU.S. Taxpayers Party\\t\\nUN\\tUnaffiliated\\t\\nUC\\tUnited Citizen\\t\\nUNI\\tUnited Party\\t\\nUNK\\tUnknown\\t\\nVET\\tVeterans Party\\t\\nWTP\\tWe the People\\t\\nW\\tWrite-In\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ACE\tAce Party\t\n",
    "AKI\tAlaskan Independence Party\t\n",
    "AIC\tAmerican Independent Conservative\t\n",
    "AIP\tAmerican Independent Party\t\n",
    "AMP\tAmerican Party\t\n",
    "APF\tAmerican People's Freedom Party\t\n",
    "AE\tAmericans Elect\t\n",
    "CIT\tCitizens' Party\t\n",
    "CMD\tCommandments Party\t\n",
    "CMP\tCommonwealth Party of the U.S.\t\n",
    "COM\tCommunist Party\t\n",
    "CNC\tConcerned Citizens Party Of Connecticut\t\n",
    "CRV\tConservative Party\t\n",
    "CON\tConstitution Party\t\n",
    "CST\tConstitutional\t\n",
    "COU\tCountry\t\n",
    "DCG\tD.C. Statehood Green Party\t\n",
    "DNL\tDemocratic -Nonpartisan League\t\n",
    "DEM\tDemocratic Party\t\n",
    "D/C\tDemocratic/Conservative\t\n",
    "DFL\tDemocratic-Farmer-Labor\t\n",
    "DGR\tDesert Green Party\t\n",
    "FED\tFederalist\t\n",
    "FLP\tFreedom Labor Party\t\n",
    "FRE\tFreedom Party\t\n",
    "GWP\tGeorge Wallace Party\t\n",
    "GRT\tGrassroots\t\n",
    "GRE\tGreen Party\t\n",
    "GR\tGreen-Rainbow\t\n",
    "HRP\tHuman Rights Party\t\n",
    "IDP\tIndependence Party\t\n",
    "IND\tIndependent\t\n",
    "IAP\tIndependent American Party\t\n",
    "ICD\tIndependent Conservative Democratic\t\n",
    "IGR\tIndependent Green\t\n",
    "IP\tIndependent Party\t\n",
    "IDE\tIndependent Party of Delaware\t\n",
    "IGD\tIndustrial Government Party\t\n",
    "JCN\tJewish/Christian National\t\n",
    "JUS\tJustice Party\t\n",
    "LRU\tLa Raza Unida\tAlso see RUP\n",
    "LBR\tLabor Party\tAlso see LAB\n",
    "LFT\tLess Federal Taxes\t\n",
    "LBL\tLiberal Party\t\n",
    "LIB\tLibertarian Party\t\n",
    "LBU\tLiberty Union Party\t\n",
    "MTP\tMountain Party\t\n",
    "NDP\tNational Democratic Party\t\n",
    "NLP\tNatural Law Party\t\n",
    "NA\tNew Alliance\t\n",
    "NJC\tNew Jersey Conservative Party\t\n",
    "NPP\tNew Progressive Party\t\n",
    "NPA\tNo Party Affiliation\t\n",
    "NOP\tNo Party Preference\tCommonly used in CA & WA\n",
    "NNE\tNone\t\n",
    "N\tNonpartisan\t\n",
    "NON\tNon-Party\t\n",
    "OE\tOne Earth Party\t\n",
    "OTH\tOther\t\n",
    "PG\tPacific Green\t\n",
    "PSL\tParty for Socialism and Liberation\t\n",
    "PAF\tPeace And Freedom\tAlso see PFP\n",
    "PFP\tPeace And Freedom Party\tAlso see PAF\n",
    "PFD\tPeace Freedom Party\t\n",
    "POP\tPeople Over Politics\t\n",
    "PPY\tPeople's Party\t\n",
    "PCH\tPersonal Choice Party\t\n",
    "PPD\tPopular Democratic Party\t\n",
    "PRO\tProgressive Party\t\n",
    "NAP\tProhibition Party\t\n",
    "PRI\tPuerto Rican Independence Party\t\n",
    "RUP\tRaza Unida Party\tAlso see LRU\n",
    "REF\tReform Party\t\n",
    "REP\tRepublican Party\t\n",
    "RES\tResource Party\t\n",
    "RTL\tRight To Life\t\n",
    "SEP\tSocialist Equality Party\t\n",
    "SLP\tSocialist Labor Party\t\n",
    "SUS\tSocialist Party\t\n",
    "SOC\tSocialist Party U.S.A.\t\n",
    "SWP\tSocialist Workers Party\t\n",
    "TX\tTaxpayers\t\n",
    "TWR\tTaxpayers Without Representation\t\n",
    "TEA\tTea Party\t\n",
    "THD\tTheo-Democratic\t\n",
    "LAB\tU.S. Labor Party\tAlso see LBR\n",
    "USP\tU.S. People's Party\t\n",
    "UST\tU.S. Taxpayers Party\t\n",
    "UN\tUnaffiliated\t\n",
    "UC\tUnited Citizen\t\n",
    "UNI\tUnited Party\t\n",
    "UNK\tUnknown\t\n",
    "VET\tVeterans Party\t\n",
    "WTP\tWe the People\t\n",
    "W\tWrite-In\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_zip_county(unique_zips, state_zips):\n",
    "    county_dict = {}\n",
    "    unique_counties = {}\n",
    "    for zipcode in unique_zips:\n",
    "        county_zip = state_zips[state_zips[\"zip\"] == zipcode]\n",
    "        county_name = county_zip[\"county\"].to_string(index=False).strip()\n",
    "        county_dict[zipcode] = county_name\n",
    "        if county_name not in unique_counties:\n",
    "            unique_counties[county_name] = True\n",
    "            \n",
    "    return (county_dict, unique_counties.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df, column_names):\n",
    "    new_frame = df.loc[:, column_names]\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    # Generate our categorical variable list\n",
    "    cat_vars = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[cat_vars]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(cat_vars)\n",
    "    \n",
    "    return encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_enc(df):\n",
    "    # Create encoder\n",
    "    le = LabelEncoder()\n",
    "    # Encode first DataFrame 1 (where all values are floats)\n",
    "    df = df.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y):\n",
    "    print(\"run_linear_regression\")\n",
    "    print(X)\n",
    "    print(y)\n",
    "    \n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25)\n",
    "    model = LinearRegression()\n",
    "    #Train the model \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Prediction!!\")\n",
    "    print(\"Confusion Matrix!!\")\n",
    "    #plot_data(X, y, y_pred)\n",
    "        \n",
    "    y_test = y_test[\"transaction_amt\"].tolist()\n",
    "    y_test = [float(i) for i in y_test]\n",
    "    \n",
    "    y_pred = numpy.concatenate( y_pred, axis=0 )\n",
    "    y_pred = y_pred.tolist()\n",
    "    print(\"Types\")\n",
    "    print(type(y_test[0]))\n",
    "    print(type(y_pred[0]))\n",
    "    print(\"values\")\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    \n",
    "    print(len(y_test))\n",
    "    print(len(y_pred))\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    print(\"Classificaiton Report!!\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25, stratify=y)\n",
    "    \n",
    "    classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type):\n",
    "    #Reduce columns to start with\n",
    "    print(df.head())\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "        \n",
    "        #Run Linear Regression Model on X,y\n",
    "        #Set Y column to just the ML model\n",
    "        y_df = select_columns(df, [sml_param])   \n",
    "        y_df = y_df.fillna(0)\n",
    "        y = label_enc(y_df)\n",
    "\n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        x_cols = sml_cols\n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        X = label_enc(X_df)\n",
    "        if model_type == 'linear':\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y)\n",
    "        elif model_type == 'logistic':\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column party to the DF that maps the committee party abbreviation to a major party\n",
    "def merge_cmtid_party(donor_df):        \n",
    "    party_repub = \"republican\"\n",
    "    party_democrat = \"democrat\"\n",
    "        \n",
    "    #Map the affiliation code to the party affiliation\n",
    "    cmte_party_map = {\n",
    "        \"REP\": party_repub,\n",
    "        \"TEA\": party_repub,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DEM\": party_democrat,\n",
    "        \"D/C\": party_democrat,\n",
    "        \"DFL\": party_democrat,\n",
    "        \"THD\": party_democrat,\n",
    "        \"PPD\": party_democrat\n",
    "    }\n",
    "    \n",
    "    donor_df[\"party\"] = donor_df[\"cmte_pty_affiliation\"].map(cmte_party_map)\n",
    "    \n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each of the election year DFs and \n",
    "def donation_county_cycle_distribution(four_yr_dfs, state_zips, committee_df):\n",
    "    if(False):\n",
    "        return [{'Maricopa': {'blue_amt': 1000, 'red_amt': 500, 'other_amt': 50, 'total_amt': 1600, 'percent_blue': .625, 'percent_red': .3125, 'percent_other': .03125}, \n",
    "                 'Pima': {'blue_amt': 2000, 'red_amt': 600, 'other_amt': 10, 'total_amt': 2610, 'percent_blue': .766, 'percent_red': .230, 'percent_other': .004}}]   \n",
    "    \n",
    "    #Organize by county\n",
    "    county_dicts = []\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        county_dict = {}\n",
    "        election_df = four_yr_dfs[i]\n",
    "        election_df.dropna(subset=[\"zip\"], inplace=True)\n",
    "            \n",
    "        unique_zips = election_df[\"zip\"].unique()\n",
    "        \n",
    "        (zip_county_map, unique_counties) = map_zip_county(unique_zips, state_zips)\n",
    "        \n",
    "        election_df[\"county\"] = election_df[\"zip\"].map(zip_county_map)\n",
    "                \n",
    "        for county in unique_counties:\n",
    "            percent_dict = donor_distribution(county, merged_df)\n",
    "            county_dict[county] = percent_dict\n",
    "        county_dicts.append(county_dict)\n",
    "    return county_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dt(donor_date_str):\n",
    "    #01/01/1996 - 12/31/1999\n",
    "    donor_date = datetime.strptime(donor_date_str, '%Y-%m-%d')\n",
    "    return donor_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_date_str(donor_date_str):\n",
    "    donor_date = str_dt(donor_date_str)\n",
    "    donor_year = donor_date.year\n",
    "    return donor_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donors_intervals(donor_df, state):\n",
    "    donors_states_df = donor_df[donor_df['state']==state.lower()]\n",
    "    \n",
    "    starting_yr = 2000\n",
    "    i = starting_yr\n",
    "    interval = 4\n",
    "    prev_year = starting_yr - interval\n",
    "    ending_yr = 2020\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "        \n",
    "    while (i <= ending_yr):\n",
    "        votes_states_interval_df = donors_states_df[(donors_states_df['transaction_dt']>datetime.date(prev_year,1,1)) & (donors_states_df['transaction_dt']<datetime.date(i,3,1))]          \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += interval\n",
    "        prev_year += interval\n",
    "        \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state, engine):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    donor_table_name = '\"fec_donor_{}\"'.format(state.lower())    \n",
    "    donor_select_sql = 'select * from {}'.format(donor_table_name)\n",
    "    donor_df = pd.read_sql_query(donor_select_sql,con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the Voter data\n",
    "def votes_linear_regression(votes_df):    \n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\"]\n",
    "    sml_cols = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\", \"state\", \"county\"]\n",
    "    \n",
    "    run_linear_regression_params(votes_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df):\n",
    "    sml_params = [\"transaction_amt\", \"employer\", \"occupation\"]\n",
    "    #sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop of the program\n",
    "def main():\n",
    "    #Read the various tables into DFs\n",
    "    health_df = pd.read_sql_query('select * from \"health_metrics\"',con=engine)\n",
    "    committee_df = pd.read_sql_query('select * from \"fec_committee\"',con=engine)\n",
    "    votes_df = pd.read_sql_query('select * from \"pres_votes_6t\"',con=engine)\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    zips_df = pd.read_sql_query('select * from \"postal_codes\"',con=engine)\n",
    "    #Lowercase the column\n",
    "    committee_df['cmte_id'] = committee_df['cmte_id'].str.lower()\n",
    "    \n",
    "    #List of swing states to run the analysis on\n",
    "    supported_states = [\"AZ\", \"MI\", \"FL\", \"NC\", \"PA\", \"WI\"]\n",
    "    \n",
    "    #Loop through each state\n",
    "    state_model_dict = {}\n",
    "    for state in supported_states:\n",
    "        #Get the votes related to that state\n",
    "        votes_intervals_df = get_votes_intervals(votes_df, state)\n",
    "\n",
    "        #Get the distribution of Red, Blue, and Other votes in a list of dict per election yr e.g. 2000 + 4n\n",
    "        counties_votes_dicts = county_vote_distribution(votes_intervals_df, state)\n",
    "        #print(counties_votes_dicts)\n",
    "        \n",
    "        #DF that has all donation for a state\n",
    "        donor_df_orig = donor_state_query(state, engine)\n",
    "        #Add party column to donor data frame\n",
    "        donor_df = committee_df.merge(donor_df_orig, left_on='cmte_id', right_on='cmt_id')\n",
    "        \n",
    "        #TODO before merging the party, we need to add the party code to the columns.\n",
    "        #donor_df = merge_cmtid_party(donor_df)\n",
    "        \n",
    "        #Run the machine learning models on the donation set\n",
    "        donation_linear_regression(donor_df)\n",
    "        \n",
    "        #TODO Once we have party, then enable logistic regression\n",
    "        #donation_logistic_regression(donor_df)\n",
    "        \n",
    "        #Get a list of DFs that for election election year for that state\n",
    "        donors_intervals_df = get_donors_intervals(donor_df, state)\n",
    "        #Filter out the zips DF by the state\n",
    "        state_zips = zips_df[zips_df[\"state\"] == state]\n",
    "        #Get list of dictionaries \n",
    "        donor_dicts = donation_county_cycle_distribution(donors_intervals_df, state_zips, committee_df)\n",
    "        #Set a tuple to pass to the functions to run machine learning\n",
    "        state_tuple = (counties_votes_dicts, donor_dicts)\n",
    "\n",
    "        state_model_dict[state] = state_tuple\n",
    "        \n",
    "        state_nn(state_tuple)\n",
    "    \n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)\n",
    "    \n",
    "    #TODO: Run Linear regression on the votes\n",
    "    #votes_linear_regression(votes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_votes_dict(votes_dict, county_votes, donor_dict):\n",
    "    votes_dict[\"blue_votes\"] = county_votes[\"blue_votes\"]\n",
    "    votes_dict[\"red_votes\"] = county_votes[\"red_votes\"]\n",
    "    votes_dict[\"other_votes\"] = county_votes[\"other_votes\"]\n",
    "    votes_dict[\"state\"] = county_votes[\"state\"]\n",
    "    votes_dict[\"county\"] = county_votes[\"county\"]\n",
    "\n",
    "    for donor_c in donor_dict:\n",
    "        if c == donor_c:\n",
    "            county_donors = donor_dict[donor_c]\n",
    "            votes_dict[\"blue_amt\"] = county_donors[\"blue_amt\"]\n",
    "            votes_dict[\"red_amt\"] = county_donors[\"red_amt\"]\n",
    "            votes_dict[\"other_amt\"] = county_donors[\"other_amt\"]\n",
    "            break\n",
    "\n",
    "    #TODO set the unemployment data\n",
    "    \"\"\"  \n",
    "    unemployment = unemployment_df[(unemployment_df[\"County\"] == c) & (unemployment_df[\"Stabr\"] == state)]\n",
    "    unemployment_col = \"Unemployment_rate_\" + str(election_yr)\n",
    "    votes_dict[\"POPPCT_URBAN\"] = pd.to_numeric(unemployment[\"POPPCT_URBAN\"].values[0])\n",
    "    votes_dict[unemployment_col] = unemployment[unemployment_col].values[0]\n",
    "    votes_dict[\"POPDEN_URBAN\"] = unemployment[\"POPDEN_URBAN\"].values[0]\n",
    "    votes_dict[\"POPPCT_RURAL\"] = unemployment[\"POPPCT_RURAL\"].values[0]\n",
    "    votes_dict[\"POPDEN_RURAL\"] = unemployment[\"POPDEN_RURAL\"].values[0]\n",
    "    \"\"\" \n",
    "    return votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_votes_dicts = state_tuple[0]    \n",
    "    donor_dicts = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_votes_dicts)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_votes_dicts[i]\n",
    "        donor_dict = donor_dicts[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_dict)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network model on the counties of votes and donors\n",
    "def run_nn(counties_votes_dict, donor_dict):\n",
    "    #Neural Networking Code\n",
    "    # Generate our categorical variable list\n",
    "    votes_mi_cat = votes_mi_df.dtypes[votes_mi_df.dtypes == \"object\"].index.tolist()\n",
    "    \n",
    "    # Check the number of unique values in each column\n",
    "    votes_mi_df[votes_mi_cat].nunique()\n",
    "    \n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(votes_mi_df[votes_mi_cat]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(votes_mi_cat)\n",
    "    encode_df.head()\n",
    "    \n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Define the model - deep neural net\n",
    "    number_input_features = len(X_train[0])\n",
    "    hidden_nodes_layer1 =  8\n",
    "    hidden_nodes_layer2 = 5\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(\n",
    "        tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    "    )\n",
    "\n",
    "    # Second hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Check the structure of the model\n",
    "    nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given each county vote distribiton and donor distribution, run neural networks.\n",
    "def state_nn(state_tuple):\n",
    "    counties_votes_dicts = state_tuple[0]\n",
    "    donor_dicts = state_tuple[1]\n",
    "    \n",
    "    for i in range(0, len(counties_votes_dicts)):\n",
    "        counties_votes_dict = counties_votes_dicts[i]\n",
    "        donor_dict = donor_dicts[i]\n",
    "        #TODO enable the nn function, requires a DF\n",
    "        #run_nn(counties_votes_dict, donor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cmte_id                    cmte_nm cmte_tp cmte_city cmte_st cmte_zip  \\\n",
      "0  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "1  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "2  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "3  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "4  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "\n",
      "  cmte_dsgn cmte_pty_affiliation org_tp connected_org_nm  ...  \\\n",
      "0         P                  REP   None             None  ...   \n",
      "1         P                  REP   None             None  ...   \n",
      "2         P                  REP   None             None  ...   \n",
      "3         P                  REP   None             None  ...   \n",
      "4         P                  REP   None             None  ...   \n",
      "\n",
      "                       employer  occupation transaction_dt transaction_amt  \\\n",
      "0  arizona endocrinology center        None     1999-04-29             250   \n",
      "1    ryley carlock & applewhite        None     1999-05-11             200   \n",
      "2          the enterprise group        None     1999-04-16            1000   \n",
      "3        concord servicing corp        None     1999-03-12             250   \n",
      "4                       retired        None     1999-04-27             200   \n",
      "\n",
      "  other_id tran_id  file_num memo_cd memo_text               sub id  \n",
      "0     None    None      None    None      None  3061920110006790000  \n",
      "1     None    None      None    None      None  3061920110006790000  \n",
      "2     None    None      None    None      None  3061920110006790000  \n",
      "3     None    None      None    None      None  3061920110006790000  \n",
      "4     None    None      None    None      None  3061920110006790000  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "run_linear_regression\n",
      "     cmt_id  city  state  zip  employer  occupation\n",
      "0         2     3      0    1         0           0\n",
      "1         2     4      0    6        17           0\n",
      "2         2     6      0   14        19           0\n",
      "3         2     2      0    6         6           0\n",
      "4         2     2      0    6        16           0\n",
      "..      ...   ...    ...  ...       ...         ...\n",
      "315       0     6      0   15         1           0\n",
      "316       0     6      0   16        10           0\n",
      "317       0     6      0   15         1           0\n",
      "318       0     6      0   16        10           0\n",
      "319       0     6      0   15         1           0\n",
      "\n",
      "[320 rows x 6 columns]\n",
      "     transaction_amt\n",
      "0                  2\n",
      "1                  1\n",
      "2                  0\n",
      "3                  2\n",
      "4                  1\n",
      "..               ...\n",
      "315                5\n",
      "316                4\n",
      "317                5\n",
      "318                4\n",
      "319                5\n",
      "\n",
      "[320 rows x 1 columns]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "Types\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "values\n",
      "[1.0, 2.0, 3.0, 4.0, 1.0, 0.0, 5.0, 0.0, 5.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 6.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 4.0, 0.0, 1.0, 3.0, 1.0, 6.0, 1.0, 0.0, 5.0, 2.0, 1.0, 0.0, 6.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 5.0, 0.0, 1.0, 5.0, 4.0, 5.0, 0.0, 0.0, 5.0, 5.0, 2.0, 1.0]\n",
      "[0.8397660782848142, 1.5864818163361285, 1.449165763338435, 5.315009775339409, 1.0318651408532364, 1.0061677125430686, 3.2411133293243077, 1.0318651408532364, 5.552757214279531, 1.3856190444512722, 1.6602511504466602, 1.1322965267956642, 1.0318651408532364, 1.323777948476268, 1.2327279127380928, 1.1365490376390985, 1.092123972418693, 1.1569942680858372, 1.0061677125430686, 1.2569433422674008, 1.364432814614104, 1.1229151765914125, 1.0318651408532364, 5.315009775339409, 1.4176335597752852, 5.315009775339409, 1.364432814614104, 1.6602511504466602, 1.449165763338435, 0.9626070052157036, 1.1365490376390985, 1.0318651408532364, 1.0318651408532364, 3.2411133293243077, 1.760682536389088, 1.0318651408532364, -0.7066580558401574, 1.1365490376390985, 1.3856190444512722, 1.260231229589106, 1.2504909261266013, 0.9626070052157036, 1.4176335597752852, 1.0318651408532364, 1.5864818163361285, 1.1569942680858372, 1.1569942680858372, 1.6602511504466602, 1.760682536389088, 1.6602511504466602, 0.9626070052157036, 1.1365490376390985, 1.323777948476268, 5.315009775339409, 1.1569942680858372, 1.4962730456170696, 1.0318651408532364, 1.260231229589106, 0.3440846575873966, 1.2569433422674008, 1.1229151765914125, 1.1322965267956642, 0.8397660782848142, 0.9626070052157036, 1.4962730456170696, 1.364432814614104, 1.092123972418693, 1.449165763338435, 5.552757214279531, 1.1322965267956642, 1.2569433422674008, 1.382331157129567, 5.315009775339409, 1.382331157129567, 1.0318651408532364, 1.1229151765914125, 1.382331157129567, 3.3611486806943573, 1.2327279127380928, 0.9626070052157036]\n",
      "80\n",
      "80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e19c65de81d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run the main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-f213eb45f944>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#Run the machine learning models on the donation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdonation_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonor_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#TODO Once we have party, then enable logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-0bffa950d4aa>\u001b[0m in \u001b[0;36mdonation_linear_regression\u001b[0;34m(donor_df)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Run some machine learning models on the donation of the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrun_linear_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-da8753a1ea1a>\u001b[0m in \u001b[0;36mrun_linear_regression_params\u001b[0;34m(df, sml_params, sml_cols)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_linear_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_sml_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-cf22749210e0>\u001b[0m in \u001b[0;36mrun_sml_params\u001b[0;34m(df, sml_params, sml_cols, model_type)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#Run Linear Regresion Model on X,y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mrun_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#Run Logistic Regresion Model on X,y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f9d46bbfccdb>\u001b[0m in \u001b[0;36mrun_linear_regression\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classificaiton Report!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#Run the main loop\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
