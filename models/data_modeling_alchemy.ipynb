{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure settings for RDS\n",
    "# Defining db info in config var\n",
    "jdbc_url=\"jdbc:postgresql://34.67.52.115/team5k\"\n",
    "config = {'user': 'postgres', \n",
    "          \"password\": \"team5kteam5k\", \n",
    "          \"driver\":\"org.postgresql.Driver\",\n",
    "          \"location\": \"34.67.52.115\",\n",
    "          \"db\": \"team5k\",\n",
    "          \"port\": \"5432\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postgres://[user]:[password]@[location]:[port]/[database]\n",
    "create_engine_str = 'postgresql://' + config[\"user\"] + \":\" + config[\"password\"] + \"@\" + config[\"location\"] + \":\" + config[\"port\"] + \"/\" + config[\"db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Postgres instance\n",
    "engine = create_engine(create_engine_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'committee_summary_2020', 'fec_donor_az', 'health_metrics', 'birth_death_rate', 'postal_codes', 'fec_donor_mi', 'fec_donor_wi', 'fec_committee', 'fec_donor_pa', 'pres_votes_6t', 'unemployment', 'fec_donor_nc', 'fec_donor_fl']\n"
     ]
    }
   ],
   "source": [
    "# Printing info for table names \n",
    "print (engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding area for function to plot data\n",
    "def plot_data(X, y, y_pred):\n",
    "    print(\"X=\" + str(len(X)))\n",
    "    print(X)\n",
    "    print(\"y=\" + str(len(y)))\n",
    "    print(y)\n",
    "    print(\"y_pred\" + str(len(y_pred)))\n",
    "    print(y_pred)\n",
    "    \n",
    "    plt.scatter(X, y)\n",
    "    plt.plot(X, y_pred, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition to take in the votes data frame. Function takes in the votes dataframe with 20 years of data. \n",
    "# This will loop thru every 4 years, runs thru all of the county votes then return it in a list. \n",
    "# This will aggregate everything and return a list in a df\n",
    "\n",
    "def get_votes_intervals(votes_df, state_po):\n",
    "    votes_states_df = votes_df[votes_df['state_po']==state_po]\n",
    "    starting_yr = 2000\n",
    "    ending_yr = 2020\n",
    "    interval = 4\n",
    "    i = starting_yr\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "    while (i <= ending_yr):\n",
    "        votes_states_interval_df = votes_states_df[votes_states_df['year']==i]    \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += interval\n",
    "    \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes thru each county (string), to pull the election date and calculate votes in the county that are democrat (blue), republic (red) and other. \n",
    "\n",
    "def vote_distribution(county, election_df, state):\n",
    "    major_parties = [\"democrat\", \"republican\"]\n",
    "        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==major_parties[0]]\n",
    "    county_red_df = county_df[county_df['party']==major_parties[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_votes = 0\n",
    "    blue_votes = pd.to_numeric(county_blue_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    red_votes = pd.to_numeric(county_red_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    unique_parties = county_df['party'].unique()\n",
    "    for party in unique_parties:\n",
    "        #Get a sum of all non major parties for other category\n",
    "        if party not in major_parties:\n",
    "            party_df = county_df[county_df['party']==party]\n",
    "            other_votes += pd.to_numeric(party_df[\"candidatevotes\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total votes it the sum of blue + red + other\n",
    "    total_votes = blue_votes + red_votes + other_votes\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_votes / total_votes)\n",
    "    percent_red = (red_votes / total_votes)\n",
    "    percent_other = (other_votes / total_votes)\n",
    "            \n",
    "    percent_dict = {\n",
    "        \"blue_votes\": blue_votes,\n",
    "        \"red_votes\": red_votes,\n",
    "        \"other_votes\": other_votes,\n",
    "        \"total_votes\": total_votes,\n",
    "        \"percent_blue\": percent_blue,\n",
    "        \"percent_red\": percent_red,\n",
    "        \"percent_other\": percent_other,\n",
    "        \"county\": county,\n",
    "        \"state\": state\n",
    "    }\n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donor_distribution(county, election_df):    \n",
    "    county = county.strip()\n",
    "    #Total sum of donations per party per county\n",
    "    major_parties = [\"democrat\", \"republican\"]\n",
    "        \n",
    "    county_df = election_df[election_df['county']==county]\n",
    "    county_blue_df = county_df[county_df['party']==major_parties[0]]\n",
    "    county_red_df = county_df[county_df['party']==major_parties[1]]  \n",
    "    \n",
    "    #Other = not democratic AND not republican  \n",
    "    other_amt = 0\n",
    "    blue_amt = pd.to_numeric(county_blue_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    red_amt = pd.to_numeric(county_red_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    #TODO enable other amount\n",
    "    other_amt =0\n",
    "    #unique_parties = county_df['party'].unique()\n",
    "    #for party in unique_parties:\n",
    "    #    #Get a sum of all non major parties for other category\n",
    "    #    if party not in major_parties:\n",
    "    #        party_df = county_df[county_df['party']==party]\n",
    "    #        other_amt += pd.to_numeric(party_df[\"transaction_amt\"].sum(), errors='coerce')\n",
    "    \n",
    "    #Total transaction amount it the sum of blue + red + other\n",
    "    total_amt = blue_amt + red_amt + other_amt\n",
    "    \n",
    "    #Get the respective percentages\n",
    "    percent_blue = (blue_amt / total_amt)\n",
    "    percent_red = (red_amt / total_amt)\n",
    "    percent_other = (other_amt / total_amt)\n",
    "            \n",
    "    percent_dict = {\n",
    "        \"blue_amt\": blue_amt,\n",
    "        \"red_amt\": red_amt,\n",
    "        \"other_amt\": other_amt,\n",
    "        \"total_amt\": total_amt,\n",
    "        \"percent_blue\": percent_blue,\n",
    "        \"percent_red\": percent_red,\n",
    "        \"percent_other\": percent_other\n",
    "    }\n",
    "    return percent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run every election year in the loop, get election df, look for the vote distribution\n",
    "# Will be run on a single state and will return a dictionary tha tcountains every county in the state as a key. \n",
    "# The value (number of votes) is a dictionary of values.\n",
    "\n",
    "def county_vote_distribution(four_yr_dfs, state):\n",
    "    #Organize by county\n",
    "    county_dicts = []\n",
    "    #Loop through each election DF\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        county_dict = {}\n",
    "        election_df = four_yr_dfs[i]\n",
    "        unique_counties = election_df[\"county\"].unique()\n",
    "        #Loop through each unique county\n",
    "        for county in unique_counties:\n",
    "            #Get the percent of the vote distribution for that county\n",
    "            percent_dict = vote_distribution(county, election_df, state)\n",
    "            county_dict[county] = percent_dict\n",
    "        county_dicts.append(county_dict)\n",
    "    return county_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nACE\\tAce Party\\t\\nAKI\\tAlaskan Independence Party\\t\\nAIC\\tAmerican Independent Conservative\\t\\nAIP\\tAmerican Independent Party\\t\\nAMP\\tAmerican Party\\t\\nAPF\\tAmerican People's Freedom Party\\t\\nAE\\tAmericans Elect\\t\\nCIT\\tCitizens' Party\\t\\nCMD\\tCommandments Party\\t\\nCMP\\tCommonwealth Party of the U.S.\\t\\nCOM\\tCommunist Party\\t\\nCNC\\tConcerned Citizens Party Of Connecticut\\t\\nCRV\\tConservative Party\\t\\nCON\\tConstitution Party\\t\\nCST\\tConstitutional\\t\\nCOU\\tCountry\\t\\nDCG\\tD.C. Statehood Green Party\\t\\nDNL\\tDemocratic -Nonpartisan League\\t\\nDEM\\tDemocratic Party\\t\\nD/C\\tDemocratic/Conservative\\t\\nDFL\\tDemocratic-Farmer-Labor\\t\\nDGR\\tDesert Green Party\\t\\nFED\\tFederalist\\t\\nFLP\\tFreedom Labor Party\\t\\nFRE\\tFreedom Party\\t\\nGWP\\tGeorge Wallace Party\\t\\nGRT\\tGrassroots\\t\\nGRE\\tGreen Party\\t\\nGR\\tGreen-Rainbow\\t\\nHRP\\tHuman Rights Party\\t\\nIDP\\tIndependence Party\\t\\nIND\\tIndependent\\t\\nIAP\\tIndependent American Party\\t\\nICD\\tIndependent Conservative Democratic\\t\\nIGR\\tIndependent Green\\t\\nIP\\tIndependent Party\\t\\nIDE\\tIndependent Party of Delaware\\t\\nIGD\\tIndustrial Government Party\\t\\nJCN\\tJewish/Christian National\\t\\nJUS\\tJustice Party\\t\\nLRU\\tLa Raza Unida\\tAlso see RUP\\nLBR\\tLabor Party\\tAlso see LAB\\nLFT\\tLess Federal Taxes\\t\\nLBL\\tLiberal Party\\t\\nLIB\\tLibertarian Party\\t\\nLBU\\tLiberty Union Party\\t\\nMTP\\tMountain Party\\t\\nNDP\\tNational Democratic Party\\t\\nNLP\\tNatural Law Party\\t\\nNA\\tNew Alliance\\t\\nNJC\\tNew Jersey Conservative Party\\t\\nNPP\\tNew Progressive Party\\t\\nNPA\\tNo Party Affiliation\\t\\nNOP\\tNo Party Preference\\tCommonly used in CA & WA\\nNNE\\tNone\\t\\nN\\tNonpartisan\\t\\nNON\\tNon-Party\\t\\nOE\\tOne Earth Party\\t\\nOTH\\tOther\\t\\nPG\\tPacific Green\\t\\nPSL\\tParty for Socialism and Liberation\\t\\nPAF\\tPeace And Freedom\\tAlso see PFP\\nPFP\\tPeace And Freedom Party\\tAlso see PAF\\nPFD\\tPeace Freedom Party\\t\\nPOP\\tPeople Over Politics\\t\\nPPY\\tPeople's Party\\t\\nPCH\\tPersonal Choice Party\\t\\nPPD\\tPopular Democratic Party\\t\\nPRO\\tProgressive Party\\t\\nNAP\\tProhibition Party\\t\\nPRI\\tPuerto Rican Independence Party\\t\\nRUP\\tRaza Unida Party\\tAlso see LRU\\nREF\\tReform Party\\t\\nREP\\tRepublican Party\\t\\nRES\\tResource Party\\t\\nRTL\\tRight To Life\\t\\nSEP\\tSocialist Equality Party\\t\\nSLP\\tSocialist Labor Party\\t\\nSUS\\tSocialist Party\\t\\nSOC\\tSocialist Party U.S.A.\\t\\nSWP\\tSocialist Workers Party\\t\\nTX\\tTaxpayers\\t\\nTWR\\tTaxpayers Without Representation\\t\\nTEA\\tTea Party\\t\\nTHD\\tTheo-Democratic\\t\\nLAB\\tU.S. Labor Party\\tAlso see LBR\\nUSP\\tU.S. People's Party\\t\\nUST\\tU.S. Taxpayers Party\\t\\nUN\\tUnaffiliated\\t\\nUC\\tUnited Citizen\\t\\nUNI\\tUnited Party\\t\\nUNK\\tUnknown\\t\\nVET\\tVeterans Party\\t\\nWTP\\tWe the People\\t\\nW\\tWrite-In\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ACE\tAce Party\t\n",
    "AKI\tAlaskan Independence Party\t\n",
    "AIC\tAmerican Independent Conservative\t\n",
    "AIP\tAmerican Independent Party\t\n",
    "AMP\tAmerican Party\t\n",
    "APF\tAmerican People's Freedom Party\t\n",
    "AE\tAmericans Elect\t\n",
    "CIT\tCitizens' Party\t\n",
    "CMD\tCommandments Party\t\n",
    "CMP\tCommonwealth Party of the U.S.\t\n",
    "COM\tCommunist Party\t\n",
    "CNC\tConcerned Citizens Party Of Connecticut\t\n",
    "CRV\tConservative Party\t\n",
    "CON\tConstitution Party\t\n",
    "CST\tConstitutional\t\n",
    "COU\tCountry\t\n",
    "DCG\tD.C. Statehood Green Party\t\n",
    "DNL\tDemocratic -Nonpartisan League\t\n",
    "DEM\tDemocratic Party\t\n",
    "D/C\tDemocratic/Conservative\t\n",
    "DFL\tDemocratic-Farmer-Labor\t\n",
    "DGR\tDesert Green Party\t\n",
    "FED\tFederalist\t\n",
    "FLP\tFreedom Labor Party\t\n",
    "FRE\tFreedom Party\t\n",
    "GWP\tGeorge Wallace Party\t\n",
    "GRT\tGrassroots\t\n",
    "GRE\tGreen Party\t\n",
    "GR\tGreen-Rainbow\t\n",
    "HRP\tHuman Rights Party\t\n",
    "IDP\tIndependence Party\t\n",
    "IND\tIndependent\t\n",
    "IAP\tIndependent American Party\t\n",
    "ICD\tIndependent Conservative Democratic\t\n",
    "IGR\tIndependent Green\t\n",
    "IP\tIndependent Party\t\n",
    "IDE\tIndependent Party of Delaware\t\n",
    "IGD\tIndustrial Government Party\t\n",
    "JCN\tJewish/Christian National\t\n",
    "JUS\tJustice Party\t\n",
    "LRU\tLa Raza Unida\tAlso see RUP\n",
    "LBR\tLabor Party\tAlso see LAB\n",
    "LFT\tLess Federal Taxes\t\n",
    "LBL\tLiberal Party\t\n",
    "LIB\tLibertarian Party\t\n",
    "LBU\tLiberty Union Party\t\n",
    "MTP\tMountain Party\t\n",
    "NDP\tNational Democratic Party\t\n",
    "NLP\tNatural Law Party\t\n",
    "NA\tNew Alliance\t\n",
    "NJC\tNew Jersey Conservative Party\t\n",
    "NPP\tNew Progressive Party\t\n",
    "NPA\tNo Party Affiliation\t\n",
    "NOP\tNo Party Preference\tCommonly used in CA & WA\n",
    "NNE\tNone\t\n",
    "N\tNonpartisan\t\n",
    "NON\tNon-Party\t\n",
    "OE\tOne Earth Party\t\n",
    "OTH\tOther\t\n",
    "PG\tPacific Green\t\n",
    "PSL\tParty for Socialism and Liberation\t\n",
    "PAF\tPeace And Freedom\tAlso see PFP\n",
    "PFP\tPeace And Freedom Party\tAlso see PAF\n",
    "PFD\tPeace Freedom Party\t\n",
    "POP\tPeople Over Politics\t\n",
    "PPY\tPeople's Party\t\n",
    "PCH\tPersonal Choice Party\t\n",
    "PPD\tPopular Democratic Party\t\n",
    "PRO\tProgressive Party\t\n",
    "NAP\tProhibition Party\t\n",
    "PRI\tPuerto Rican Independence Party\t\n",
    "RUP\tRaza Unida Party\tAlso see LRU\n",
    "REF\tReform Party\t\n",
    "REP\tRepublican Party\t\n",
    "RES\tResource Party\t\n",
    "RTL\tRight To Life\t\n",
    "SEP\tSocialist Equality Party\t\n",
    "SLP\tSocialist Labor Party\t\n",
    "SUS\tSocialist Party\t\n",
    "SOC\tSocialist Party U.S.A.\t\n",
    "SWP\tSocialist Workers Party\t\n",
    "TX\tTaxpayers\t\n",
    "TWR\tTaxpayers Without Representation\t\n",
    "TEA\tTea Party\t\n",
    "THD\tTheo-Democratic\t\n",
    "LAB\tU.S. Labor Party\tAlso see LBR\n",
    "USP\tU.S. People's Party\t\n",
    "UST\tU.S. Taxpayers Party\t\n",
    "UN\tUnaffiliated\t\n",
    "UC\tUnited Citizen\t\n",
    "UNI\tUnited Party\t\n",
    "UNK\tUnknown\t\n",
    "VET\tVeterans Party\t\n",
    "WTP\tWe the People\t\n",
    "W\tWrite-In\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_zip_county(unique_zips, state_zips):\n",
    "    county_dict = {}\n",
    "    unique_counties = {}\n",
    "    for zipcode in unique_zips:\n",
    "        county_zip = state_zips[state_zips[\"zip\"] == zipcode]\n",
    "        county_name = county_zip[\"county\"].to_string(index=False).strip()\n",
    "        county_dict[zipcode] = county_name\n",
    "        if county_name not in unique_counties:\n",
    "            unique_counties[county_name] = True\n",
    "            \n",
    "    return (county_dict, unique_counties.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(df, column_names):\n",
    "    new_frame = df.loc[:, column_names]\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    # Generate our categorical variable list\n",
    "    cat_vars = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[cat_vars]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(cat_vars)\n",
    "    \n",
    "    return encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_enc(df):\n",
    "    # Create encoder\n",
    "    le = LabelEncoder()\n",
    "    # Encode first DataFrame 1 (where all values are floats)\n",
    "    df = df.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(X, y, x_cols):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25)\n",
    "    model = LinearRegression()\n",
    "    #Train the model \n",
    "    model.fit(X_train, y_train)\n",
    "    #Predict the values based on the X test values\n",
    "    \n",
    "    X_test_scaled = MinMaxScaler().fit_transform(X_test)\n",
    "    \n",
    "    print(\"Test Vals!!\")\n",
    "    print(X)\n",
    "    print(y)\n",
    "    #print(X.head())\n",
    "    #print(y.head())\n",
    "    #print(X_test.head())\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(y_pred)\n",
    "        \n",
    "    print(\"Prediction!!\")\n",
    "    print(\"Confusion Matrix!!\")\n",
    "    #y_test = y_test[\"transaction_amt\"].tolist()\n",
    "    y_test = [int(i) for i in y_test]\n",
    "    \n",
    "    # [[1], [2], [3]] => [1,2,3]\n",
    "    #y_pred = numpy.concatenate(y_pred, axis=0 )\n",
    "    #y_pred = y_pred.tolist()\n",
    "    y_pred = [int(i) for i in y_pred]\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(matrix)\n",
    "    print(\"Classificaiton Report!!\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X, y):\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.25, stratify=y)\n",
    "    \n",
    "    classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_params(df, sml_params, sml_cols):\n",
    "    run_sml_params(df, sml_params, sml_cols, \"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sml_params(df, sml_params, sml_cols, model_type):\n",
    "    #Reduce columns to start with\n",
    "    print(df.head())\n",
    "    for sml_param in sml_params:\n",
    "        df_all = select_columns(df, sml_cols)     \n",
    "        \n",
    "        #Run Linear Regression Model on X,y\n",
    "        #Set Y column to just the ML model\n",
    "        y_df = select_columns(df, [sml_param])   \n",
    "        y_df = y_df.fillna(0)\n",
    "        y_df = label_enc(y_df)\n",
    "        y = y_df[sml_param].values\n",
    "        \n",
    "        print(\"Y head\")\n",
    "        print(y)\n",
    "\n",
    "        #Set X Cols to the everything but the parameter to run the ML model\n",
    "        x_cols = sml_cols\n",
    "        x_cols.remove(sml_param)\n",
    "        X_df = select_columns(df, x_cols)\n",
    "        X_df = X_df.fillna(0)\n",
    "        X_df = label_enc(X_df)\n",
    "        X = X_df[x_cols].values\n",
    "        \n",
    "        print(\"X head\")\n",
    "        print(X)\n",
    "        \n",
    "        if model_type == 'linear':\n",
    "            #Run Linear Regresion Model on X,y\n",
    "            run_linear_regression(X, y, x_cols)\n",
    "        elif model_type == 'logistic':\n",
    "            #Run Logistic Regresion Model on X,y\n",
    "            run_logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column party to the DF that maps the committee party abbreviation to a major party\n",
    "def merge_cmtid_party(donor_df):        \n",
    "    party_repub = \"republican\"\n",
    "    party_democrat = \"democrat\"\n",
    "        \n",
    "    #Map the affiliation code to the party affiliation\n",
    "    cmte_party_map = {\n",
    "        \"REP\": party_repub,\n",
    "        \"TEA\": party_repub,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DNL\": party_democrat,\n",
    "        \"DEM\": party_democrat,\n",
    "        \"D/C\": party_democrat,\n",
    "        \"DFL\": party_democrat,\n",
    "        \"THD\": party_democrat,\n",
    "        \"PPD\": party_democrat\n",
    "    }\n",
    "    \n",
    "    donor_df[\"party\"] = donor_df[\"cmte_pty_affiliation\"].map(cmte_party_map)\n",
    "    \n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each of the election year DFs and \n",
    "def donation_county_cycle_distribution(four_yr_dfs, state_zips, committee_df):\n",
    "    if(False):\n",
    "        return [{'Maricopa': {'blue_amt': 1000, 'red_amt': 500, 'other_amt': 50, 'total_amt': 1600, 'percent_blue': .625, 'percent_red': .3125, 'percent_other': .03125}, \n",
    "                 'Pima': {'blue_amt': 2000, 'red_amt': 600, 'other_amt': 10, 'total_amt': 2610, 'percent_blue': .766, 'percent_red': .230, 'percent_other': .004}}]   \n",
    "    \n",
    "    #Organize by county\n",
    "    county_dicts = []\n",
    "    for i in range(len(four_yr_dfs)):\n",
    "        county_dict = {}\n",
    "        election_df = four_yr_dfs[i]\n",
    "        election_df.dropna(subset=[\"zip\"], inplace=True)\n",
    "            \n",
    "        unique_zips = election_df[\"zip\"].unique()\n",
    "        \n",
    "        (zip_county_map, unique_counties) = map_zip_county(unique_zips, state_zips)\n",
    "        \n",
    "        election_df[\"county\"] = election_df[\"zip\"].map(zip_county_map)\n",
    "                \n",
    "        for county in unique_counties:\n",
    "            percent_dict = donor_distribution(county, election_df)\n",
    "            county_dict[county] = percent_dict\n",
    "        county_dicts.append(county_dict)\n",
    "    return county_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dt(donor_date_str):\n",
    "    #01/01/1996 - 12/31/1999\n",
    "    donor_date = datetime.strptime(donor_date_str, '%Y-%m-%d')\n",
    "    return donor_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_date_str(donor_date_str):\n",
    "    donor_date = str_dt(donor_date_str)\n",
    "    donor_year = donor_date.year\n",
    "    return donor_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donors_intervals(donor_df, state):\n",
    "    donors_states_df = donor_df[donor_df['state']==state.lower()]\n",
    "    \n",
    "    starting_yr = 2000\n",
    "    i = starting_yr\n",
    "    interval = 4\n",
    "    prev_year = starting_yr - interval\n",
    "    ending_yr = 2020\n",
    "    \n",
    "    four_yr_dfs = []\n",
    "        \n",
    "    while (i <= ending_yr):\n",
    "        votes_states_interval_df = donors_states_df[(donors_states_df['transaction_dt']>datetime.date(prev_year,1,1)) & (donors_states_df['transaction_dt']<datetime.date(i,3,1))]          \n",
    "        four_yr_dfs.append(votes_states_interval_df)\n",
    "        i += interval\n",
    "        prev_year += interval\n",
    "        \n",
    "    return four_yr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all donation records for a single state and return it in a dataframe\n",
    "def donor_state_query(state, engine):\n",
    "    #Run queries to get all donation records from the states into dfs\n",
    "    donor_table_name = '\"fec_donor_{}\"'.format(state.lower())    \n",
    "    donor_select_sql = 'select * from {}'.format(donor_table_name)\n",
    "    donor_df = pd.read_sql_query(donor_select_sql,con=engine)\n",
    "    return donor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the Voter data\n",
    "def votes_linear_regression(votes_df):    \n",
    "    sml_params = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\"]\n",
    "    sml_cols = [\"blue_votes\", \"red_votes\", \"other_votes\", \"blue_amt\", \"red_amt\", \"other_amt\", \"state\", \"county\"]\n",
    "    \n",
    "    run_linear_regression_params(votes_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donation_logistic_regression(donor_df):\n",
    "    sml_params = [\"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    \n",
    "    #Run logistic regression to test if we can classify the party\n",
    "    run_logistic_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning models run on the donation data\n",
    "def donation_linear_regression(donor_df):\n",
    "    sml_params = [\"transaction_amt\", \"employer\", \"occupation\"]\n",
    "    #sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\", \"party\"]\n",
    "    sml_cols = [\"cmt_id\", \"city\", \"state\", \"zip\", \"employer\", \"occupation\", \"transaction_amt\"]\n",
    "    \n",
    "    #Run some machine learning models on the donation of the state\n",
    "    run_linear_regression_params(donor_df, sml_params, sml_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_votes_linear_regression(state_model_dict):\n",
    "    election_yr = 2000\n",
    "    unemployment_df = pd.read_sql_query('select * from \"unemployment\"',con=engine)\n",
    "    education_df = pd.read_sql_query('select * from \"education\"',con=engine)\n",
    "    birth_death_df = pd.read_sql_query('select * from \"birth_death_rate\"',con=engine)\n",
    "    for state in state_model_dict.keys():\n",
    "        model = state_model_dict[state]\n",
    "        #TODO enable prediction for voting\n",
    "        #state_sml(model, state, election_yr, unemployment_df, education_df, birth_death_df)\n",
    "        election_yr += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Loop of the program\n",
    "def main():\n",
    "    #Read the various tables into DFs\n",
    "    health_df = pd.read_sql_query('select * from \"health_metrics\"',con=engine)\n",
    "    committee_df = pd.read_sql_query('select * from \"fec_committee\"',con=engine)\n",
    "    votes_df = pd.read_sql_query('select * from \"pres_votes_6t\"',con=engine)\n",
    "    zips_df = pd.read_sql_query('select * from \"postal_codes\"',con=engine)\n",
    "    \n",
    "    #Lowercase the column\n",
    "    committee_df['cmte_id'] = committee_df['cmte_id'].str.lower()\n",
    "    \n",
    "    #List of swing states to run the analysis on\n",
    "    supported_states = [\"AZ\", \"MI\", \"FL\", \"NC\", \"PA\", \"WI\"]\n",
    "    \n",
    "    #Loop through each state\n",
    "    state_model_dict = {}\n",
    "    for state in supported_states:\n",
    "        #Get the votes related to that state\n",
    "        votes_intervals_df = get_votes_intervals(votes_df, state)\n",
    "\n",
    "        #Get the distribution of Red, Blue, and Other votes in a list of dict per election yr e.g. 2000 + 4n\n",
    "        counties_votes_dicts = county_vote_distribution(votes_intervals_df, state)\n",
    "        #print(counties_votes_dicts)\n",
    "        \n",
    "        #DF that has all donation for a state\n",
    "        donor_df_orig = donor_state_query(state, engine)\n",
    "        #Add party column to donor data frame\n",
    "        donor_df = committee_df.merge(donor_df_orig, left_on='cmte_id', right_on='cmt_id')\n",
    "        \n",
    "        #TODO before merging the party, we need to add the party code to the columns.\n",
    "        donor_df = merge_cmtid_party(donor_df)\n",
    "        \n",
    "        #Run the machine learning models on the donation set\n",
    "        donation_linear_regression(donor_df)\n",
    "        \n",
    "        #TODO Once we have full dataset, then enable logistic regression\n",
    "        #donation_logistic_regression(donor_df)\n",
    "        \n",
    "        #Get a list of DFs that for election election year for that state\n",
    "        donors_intervals_df = get_donors_intervals(donor_df, state)\n",
    "        #Filter out the zips DF by the state\n",
    "        state_zips = zips_df[zips_df[\"state\"] == state]\n",
    "        #Get list of dictionaries \n",
    "        donor_dicts = donation_county_cycle_distribution(donors_intervals_df, state_zips, committee_df)\n",
    "        #Set a tuple to pass to the functions to run machine learning\n",
    "        state_tuple = (counties_votes_dicts, donor_dicts)\n",
    "\n",
    "        state_model_dict[state] = state_tuple\n",
    "        \n",
    "        #TODO enable the neural networking code\n",
    "        #state_nn(state_tuple)\n",
    "    \n",
    "    #TODO: Now with all states donations and voting results aggregated, predict the number of votes\n",
    "    #predict_votes_linear_regression(state_model_dict)\n",
    "    \n",
    "    #TODO: Run Linear regression on the votes\n",
    "    #votes_linear_regression(votes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_votes_dict(votes_dict, county_votes, donor_dict):\n",
    "    votes_dict[\"blue_votes\"] = county_votes[\"blue_votes\"]\n",
    "    votes_dict[\"red_votes\"] = county_votes[\"red_votes\"]\n",
    "    votes_dict[\"other_votes\"] = county_votes[\"other_votes\"]\n",
    "    votes_dict[\"state\"] = county_votes[\"state\"]\n",
    "    votes_dict[\"county\"] = county_votes[\"county\"]\n",
    "\n",
    "    for donor_c in donor_dict:\n",
    "        if c == donor_c:\n",
    "            county_donors = donor_dict[donor_c]\n",
    "            votes_dict[\"blue_amt\"] = county_donors[\"blue_amt\"]\n",
    "            votes_dict[\"red_amt\"] = county_donors[\"red_amt\"]\n",
    "            votes_dict[\"other_amt\"] = county_donors[\"other_amt\"]\n",
    "            break\n",
    "\n",
    "    #TODO set the unemployment data\n",
    "    \"\"\"  \n",
    "    unemployment = unemployment_df[(unemployment_df[\"County\"] == c) & (unemployment_df[\"Stabr\"] == state)]\n",
    "    unemployment_col = \"Unemployment_rate_\" + str(election_yr)\n",
    "    votes_dict[\"POPPCT_URBAN\"] = pd.to_numeric(unemployment[\"POPPCT_URBAN\"].values[0])\n",
    "    votes_dict[unemployment_col] = unemployment[unemployment_col].values[0]\n",
    "    votes_dict[\"POPDEN_URBAN\"] = unemployment[\"POPDEN_URBAN\"].values[0]\n",
    "    votes_dict[\"POPPCT_RURAL\"] = unemployment[\"POPPCT_RURAL\"].values[0]\n",
    "    votes_dict[\"POPDEN_RURAL\"] = unemployment[\"POPDEN_RURAL\"].values[0]\n",
    "    \"\"\" \n",
    "    return votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define the Linear Regression Structured Machine Learning\n",
    "def state_sml(state_tuple, state, election_yr, unemployment_df, education_df, birth_death_df):\n",
    "    #TODO merge together relevant info for county from unemployment_df, education_df, birth_death_df\n",
    "    counties_votes_dicts = state_tuple[0]    \n",
    "    donor_dicts = state_tuple[1]\n",
    "    \n",
    "    #Loop through each election year county dict\n",
    "    for i in range(0, len(counties_votes_dicts)):\n",
    "        #Select the corresponding counties/votes and donor info for that election yr\n",
    "        counties_votes_dict = counties_votes_dicts[i]\n",
    "        donor_dict = donor_dicts[i]\n",
    "        \n",
    "        county_dict = {}\n",
    "        #Loop through all the votes organized by county\n",
    "        for c in counties_votes_dict:\n",
    "            #Kepp unique dict of counties\n",
    "            if c not in county_dict:\n",
    "                county_dict[c] = {}\n",
    "            #Get the number of votes by county\n",
    "            county_votes = counties_votes_dict[c]\n",
    "            #Update the vote dict\n",
    "            votes_dict = set_votes_dict(county_dict[c], county_votes, donor_dict)\n",
    "            #Update the county dict with the updated votes dict\n",
    "            county_dict[c] = votes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network model on the counties of votes and donors\n",
    "def run_nn_print(counties_votes_dict, donor_dict):\n",
    "    print(\"run_nn_print\")\n",
    "    print(counties_votes_dict)\n",
    "    print(donor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the neural network model on the counties of votes and donors\n",
    "def run_nn(counties_votes_dict, donor_dict):\n",
    "    #Neural Networking Code\n",
    "    nn_df = pd.DataFrame(counties_votes_dict)\n",
    "    \n",
    "    # Generate our categorical variable list\n",
    "    votes_mi_cat = nn_df.dtypes[nn_df.dtypes == \"object\"].index.tolist()\n",
    "    \n",
    "    # Check the number of unique values in each column\n",
    "    nn_df[votes_mi_cat].nunique()\n",
    "    \n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(nn_df[votes_mi_cat]))\n",
    "\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(votes_mi_cat)\n",
    "    encode_df.head()\n",
    "    \n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Define the model - deep neural net\n",
    "    number_input_features = len(X_train[0])\n",
    "    hidden_nodes_layer1 =  8\n",
    "    hidden_nodes_layer2 = 5\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(\n",
    "        tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    "    )\n",
    "\n",
    "    # Second hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Check the structure of the model\n",
    "    nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given each county vote distribiton and donor distribution, run neural networks.\n",
    "def state_nn(state_tuple):\n",
    "    counties_votes_dicts = state_tuple[0]\n",
    "    donor_dicts = state_tuple[1]\n",
    "    \n",
    "    for i in range(0, len(counties_votes_dicts)):\n",
    "        counties_votes_dict = counties_votes_dicts[i]\n",
    "        donor_dict = donor_dicts[i]\n",
    "        #TODO enable the nn function, requires a DF\n",
    "        run_nn(counties_votes_dict, donor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cmte_id                    cmte_nm cmte_tp cmte_city cmte_st cmte_zip  \\\n",
      "0  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "1  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "2  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "3  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "4  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "\n",
      "  cmte_dsgn cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0         P                  REP   None             None  ...       None   \n",
      "1         P                  REP   None             None  ...       None   \n",
      "2         P                  REP   None             None  ...       None   \n",
      "3         P                  REP   None             None  ...       None   \n",
      "4         P                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-04-29             250     None    None     None     None   \n",
      "1      1999-05-11             200     None    None     None     None   \n",
      "2      1999-04-16            1000     None    None     None     None   \n",
      "3      1999-03-12             250     None    None     None     None   \n",
      "4      1999-04-27             200     None    None     None     None   \n",
      "\n",
      "  memo_text               sub id       party  \n",
      "0      None  3061920110006790000  republican  \n",
      "1      None  3061920110006790000  republican  \n",
      "2      None  3061920110006790000  republican  \n",
      "3      None  3061920110006790000  republican  \n",
      "4      None  3061920110006790000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3\n",
      " 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1\n",
      " 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0\n",
      " 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0\n",
      " 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1\n",
      " 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1\n",
      " 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6\n",
      " 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 0 0 4 5 4 5 4 5 4 5 4 5 4 5 4 5 4 5]\n",
      "X head\n",
      "[[ 2  3  0  1  0  0]\n",
      " [ 2  4  0  6 17  0]\n",
      " [ 2  6  0 14 19  0]\n",
      " ...\n",
      " [ 0  6  0 15  1  0]\n",
      " [ 0  6  0 16 10  0]\n",
      " [ 0  6  0 15  1  0]]\n",
      "Test Vals!!\n",
      "[[ 2  3  0  1  0  0]\n",
      " [ 2  4  0  6 17  0]\n",
      " [ 2  6  0 14 19  0]\n",
      " ...\n",
      " [ 0  6  0 15  1  0]\n",
      " [ 0  6  0 16 10  0]\n",
      " [ 0  6  0 15  1  0]]\n",
      "[2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3\n",
      " 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1\n",
      " 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0\n",
      " 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0\n",
      " 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1\n",
      " 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1\n",
      " 1 0 0 0 0 1 0 6 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6\n",
      " 1 0 2 1 0 2 1 2 0 3 0 2 1 1 2 5 0 1 3 0 1 1 0 0 0 0 1 0 6 1 0 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 0 0 4 5 4 5 4 5 4 5 4 5 4 5 4 5 4 5]\n",
      "[4.31606246 4.3271945  4.32017877 5.75647779 4.28471263 4.33943342\n",
      " 5.0524316  4.28471263 5.76851508 4.31715136 4.33118281 4.2897342\n",
      " 4.28471263 4.32761095 4.29475577 4.34550271 4.28772558 4.34742452\n",
      " 4.33943342 4.32456907 4.3574966  4.31756781 4.28471263 5.75647779\n",
      " 4.33260358 5.75647779 4.3574966  4.33118281 4.32017877 4.26634877\n",
      " 4.34550271 4.28471263 4.28471263 5.0524316  4.33620438 4.28471263\n",
      " 3.62558786 4.34550271 4.31715136 4.32458354 4.35149966 4.26634877\n",
      " 4.33260358 4.28471263 4.3271945  4.34742452 4.34742452 4.33118281\n",
      " 4.33620438 4.33118281 4.26634877 4.34550271 4.32761095 5.75647779\n",
      " 4.34742452 4.32313383 4.28471263 4.32458354 4.219922   4.32456907\n",
      " 4.31756781 4.2897342  4.31606246 4.26634877 4.32313383 4.3574966\n",
      " 4.28772558 4.32017877 5.76851508 4.2897342  4.32456907 4.31713689\n",
      " 5.75647779 4.31713689 4.28471263 4.31756781 4.31713689 5.03058047\n",
      " 4.29475577 4.26634877]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[ 0  0  0  1 23  0  0]\n",
      " [ 0  0  0  0 22  0  0]\n",
      " [ 0  0  0  0 10  0  0]\n",
      " [ 0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  0  0  3  5  0]\n",
      " [ 0  0  0  0  4  0  0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.50      0.62      0.56         8\n",
      "           6       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.06        80\n",
      "   macro avg       0.07      0.09      0.08        80\n",
      "weighted avg       0.05      0.06      0.06        80\n",
      "\n",
      "Y head\n",
      "[ 0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4\n",
      "  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7\n",
      " 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16\n",
      " 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14\n",
      " 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6\n",
      " 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16\n",
      " 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4\n",
      "  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16\n",
      "  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16\n",
      " 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7\n",
      " 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19\n",
      "  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4\n",
      " 16 16 15 19 15 19 15 19 15 19 15 19 15 19 12 12 10  1 10  1 10  1 10  1\n",
      " 10  1 10  1 10  1 10  1]\n",
      "X head\n",
      "[[ 2  3  0  1  0]\n",
      " [ 2  4  0  6  0]\n",
      " [ 2  6  0 14  0]\n",
      " ...\n",
      " [ 0  6  0 15  0]\n",
      " [ 0  6  0 16  0]\n",
      " [ 0  6  0 15  0]]\n",
      "Test Vals!!\n",
      "[[ 2  3  0  1  0]\n",
      " [ 2  4  0  6  0]\n",
      " [ 2  6  0 14  0]\n",
      " ...\n",
      " [ 0  6  0 15  0]\n",
      " [ 0  6  0 16  0]\n",
      " [ 0  6  0 15  0]]\n",
      "[ 0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4\n",
      "  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7\n",
      " 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16\n",
      " 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14\n",
      " 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6\n",
      " 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16\n",
      " 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4\n",
      "  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16\n",
      "  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7 14 13  9  5 16\n",
      " 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19  6 16  3 14  7\n",
      " 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4 16 16  0 17 19\n",
      "  6 16  3 14  7 14 13  9  5 16 16 11 16 20 16  7 13 18  8  4  4  2  4  4\n",
      " 16 16 15 19 15 19 15 19 15 19 15 19 15 19 12 12 10  1 10  1 10  1 10  1\n",
      " 10  1 10  1 10  1 10  1]\n",
      "[9.32597406 9.35650374 9.34026558 8.47894294 9.19314873 9.52180541\n",
      " 9.04908868 9.19314873 8.4951811  9.35650374 9.38898008 9.19314873\n",
      " 9.19314873 9.38995341 9.19314873 9.47309091 9.19314873 9.57051991\n",
      " 9.52180541 9.42242975 9.53804358 9.38995341 9.19314873 8.47894294\n",
      " 9.42242975 8.47894294 9.53804358 9.38898008 9.34026558 9.01355556\n",
      " 9.47309091 9.19314873 9.19314873 9.04908868 9.38898008 9.19314873\n",
      " 9.94386098 9.47309091 9.35650374 9.40619158 9.50556724 9.01355556\n",
      " 9.42242975 9.19314873 9.35650374 9.57051991 9.57051991 9.38898008\n",
      " 9.38898008 9.38898008 9.01355556 9.47309091 9.38995341 8.47894294\n",
      " 9.57051991 9.40521825 9.19314873 9.40619158 8.76900971 9.42242975\n",
      " 9.38995341 9.19314873 9.32597406 9.01355556 9.40521825 9.53804358\n",
      " 9.19314873 9.34026558 8.4951811  9.19314873 9.42242975 9.37274191\n",
      " 8.47894294 9.37274191 9.19314873 9.38995341 9.37274191 8.90099851\n",
      " 9.19314873 9.01355556]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         5\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.03      1.00      0.05         2\n",
      "          10       0.00      0.00      0.00         5\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         4\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00        15\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.03        80\n",
      "   macro avg       0.00      0.05      0.00        80\n",
      "weighted avg       0.00      0.03      0.00        80\n",
      "\n",
      "Y head\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X head\n",
      "[[ 2  3  0  1]\n",
      " [ 2  4  0  6]\n",
      " [ 2  6  0 14]\n",
      " ...\n",
      " [ 0  6  0 15]\n",
      " [ 0  6  0 16]\n",
      " [ 0  6  0 15]]\n",
      "Test Vals!!\n",
      "[[ 2  3  0  1]\n",
      " [ 2  4  0  6]\n",
      " [ 2  6  0 14]\n",
      " ...\n",
      " [ 0  6  0 15]\n",
      " [ 0  6  0 16]\n",
      " [ 0  6  0 15]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[80]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "     cmte_id                    cmte_nm cmte_tp cmte_city cmte_st cmte_zip  \\\n",
      "0  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "1  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "2  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "3  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "4  c00280453  JOHN SHADEGG FOR CONGRESS       H  PHOENIX,      AZ    85064   \n",
      "\n",
      "  cmte_dsgn cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0         P                  REP   None             None  ...       None   \n",
      "1         P                  REP   None             None  ...       None   \n",
      "2         P                  REP   None             None  ...       None   \n",
      "3         P                  REP   None             None  ...       None   \n",
      "4         P                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-04-29             250     None    None     None     None   \n",
      "1      1999-05-11             200     None    None     None     None   \n",
      "2      1999-04-16            1000     None    None     None     None   \n",
      "3      1999-03-12             250     None    None     None     None   \n",
      "4      1999-04-27             200     None    None     None     None   \n",
      "\n",
      "  memo_text               sub id       party  \n",
      "0      None  3061920110006790000  republican  \n",
      "1      None  3061920110006790000  republican  \n",
      "2      None  3061920110006790000  republican  \n",
      "3      None  3061920110006790000  republican  \n",
      "4      None  3061920110006790000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X head\n",
      "[[ 2  3  0 ...  0  0  2]\n",
      " [ 2  4  0 ... 17  0  1]\n",
      " [ 2  6  0 ... 19  0  0]\n",
      " ...\n",
      " [ 0  6  0 ...  1  0  5]\n",
      " [ 0  6  0 ... 10  0  4]\n",
      " [ 0  6  0 ...  1  0  5]]\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cmte_id              cmte_nm cmte_tp cmte_city cmte_st cmte_zip  \\\n",
      "0  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "1  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "2  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "3  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "4  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "\n",
      "  cmte_dsgn cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0         P                  REP   None             None  ...       None   \n",
      "1         P                  REP   None             None  ...       None   \n",
      "2         P                  REP   None             None  ...       None   \n",
      "3         P                  REP   None             None  ...       None   \n",
      "4         P                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-06-11             667     None    None     None     None   \n",
      "1      1999-06-07             333     None    None     None     None   \n",
      "2      1999-06-18             250     None    None     None     None   \n",
      "3      1999-06-18             250     None    None     None     None   \n",
      "4      1999-06-14             200     None    None     None     None   \n",
      "\n",
      "  memo_text               sub id       party  \n",
      "0      None  3061920110007030000  republican  \n",
      "1      None  3061920110007030000  republican  \n",
      "2      None  3061920110007030000  republican  \n",
      "3      None  3061920110007030000  republican  \n",
      "4      None  3061920110007030000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1\n",
      " 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4\n",
      " 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4\n",
      " 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3\n",
      " 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0\n",
      " 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0\n",
      " 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3\n",
      " 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 6 0 6 0 7 3 3 7\n",
      " 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3\n",
      " 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3\n",
      " 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7\n",
      " 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7]\n",
      "X head\n",
      "[[ 3  1  0  4 20  0]\n",
      " [ 3  1  0  4 20  0]\n",
      " [ 3  0  0  1 23  0]\n",
      " ...\n",
      " [ 0  7  0 18 23  0]\n",
      " [ 0  7  0 18 23  0]\n",
      " [ 1  6  0  0 14  0]]\n",
      "Test Vals!!\n",
      "[[ 3  1  0  4 20  0]\n",
      " [ 3  1  0  4 20  0]\n",
      " [ 3  0  0  1 23  0]\n",
      " ...\n",
      " [ 0  7  0 18 23  0]\n",
      " [ 0  7  0 18 23  0]\n",
      " [ 1  6  0  0 14  0]]\n",
      "[8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1\n",
      " 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4\n",
      " 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4\n",
      " 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3\n",
      " 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0\n",
      " 0 7 0 0 0 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0\n",
      " 9 7 8 5 3 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 8 5 3\n",
      " 3 1 4 4 4 4 4 1 7 4 1 4 3 3 3 3 3 3 6 4 0 0 0 7 0 0 0 9 7 6 0 6 0 7 3 3 7\n",
      " 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3\n",
      " 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3\n",
      " 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7\n",
      " 3 3 3 7 7 7 3 3 7 7 3 7 7 2 7 3 3 3 7 7 7]\n",
      "[6.94024775 6.99039158 8.15552412 7.05173124 7.08005104 8.15552412\n",
      " 7.05239039 8.15552412 8.15552412 8.30323724 8.16615654 7.05865234\n",
      " 6.98546614 7.05239039 6.99645781 7.05173124 8.14851703 7.06515233\n",
      " 7.05634531 7.0168339  8.15552412 8.15552412 7.05832276 7.08005104\n",
      " 7.05173124 7.05041293 8.15552412 7.00254225 7.05634531 7.05239039\n",
      " 8.14686915 8.15552412 8.14489169 7.05041293 6.94024775 7.05733403\n",
      " 6.99313238 8.14489169 6.99313238 7.05239039 8.15552412 6.98546614\n",
      " 6.99039158 8.14489169 7.07156634 8.15552412 7.05865234 6.98676624\n",
      " 7.0168339  7.06515233 8.15552412 7.05271997 6.99039158 7.0649706\n",
      " 7.05832276 6.94024775 7.08005104 6.99645781 7.05173124 7.08005104\n",
      " 7.05173124 7.05634531 7.05832276 7.05173124 7.05041293 8.15552412\n",
      " 6.99313238 6.98676624 6.99203946 7.0649706  8.15552412 7.05832276\n",
      " 7.93590244 8.16615654 8.14851703 7.05832276 7.05865234 7.05041293\n",
      " 6.99203946 6.99203946 7.08005104 7.05832276 7.07156634 6.99203946\n",
      " 7.05733403 6.94024775 6.99645781 7.05173124 7.05271997 7.05865234\n",
      " 7.05239039 7.05832276 7.00254225 7.05733403 8.15552412 6.98546614\n",
      " 8.15552412 7.05271997 8.14686915 7.05832276 8.15552412 7.05832276\n",
      " 7.05634531 7.055027   7.05173124 7.05832276 7.05832276]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[ 0  0  0  0  0  4 10  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0 15  7 12  0]\n",
      " [ 0  0  0  0  0  0 22  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  3 10 14  0]\n",
      " [ 0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.17      0.37      0.23        27\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.09       107\n",
      "   macro avg       0.02      0.04      0.03       107\n",
      "weighted avg       0.04      0.09      0.06       107\n",
      "\n",
      "Y head\n",
      "[20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23\n",
      " 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23\n",
      " 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24\n",
      " 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23\n",
      " 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12\n",
      " 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 14]\n",
      "X head\n",
      "[[ 3  1  0  4  0]\n",
      " [ 3  1  0  4  0]\n",
      " [ 3  0  0  1  0]\n",
      " ...\n",
      " [ 0  7  0 18  0]\n",
      " [ 0  7  0 18  0]\n",
      " [ 1  6  0  0  0]]\n",
      "Test Vals!!\n",
      "[[ 3  1  0  4  0]\n",
      " [ 3  1  0  4  0]\n",
      " [ 3  0  0  1  0]\n",
      " ...\n",
      " [ 0  7  0 18  0]\n",
      " [ 0  7  0 18  0]\n",
      " [ 1  6  0  0  0]]\n",
      "[20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7\n",
      "  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21 23 23 26  6  4 11  3 16\n",
      "  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3 20 20 23 23 23 16  9 21\n",
      " 23 23 26  6  4 11  3 16  0 10  8  5 18 13 22  7  7  1 19  2  2 27  3  3\n",
      " 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23\n",
      " 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23\n",
      " 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24\n",
      " 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23\n",
      " 23 23 23 23 15 24 25 23 12 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12\n",
      " 23 23 23 23 17 23 23 23 23 23 15 24 25 23 12 23 23 23 23 14]\n",
      "[22.78621031 22.79334884 26.89493334 22.92398903 22.97342526 26.89493334\n",
      " 22.92398903 26.89493334 26.89493334 27.08214829 26.92670107 22.92398903\n",
      " 23.06498137 22.92398903 22.77924961 22.92398903 26.86316561 23.21329006\n",
      " 22.92398903 22.94861824 26.89493334 26.89493334 22.92398903 22.97342526\n",
      " 22.92398903 22.92398903 26.89493334 23.0367829  22.92398903 22.92398903\n",
      " 26.86316561 26.89493334 26.86316561 22.92398903 22.78621031 22.92398903\n",
      " 23.0967491  26.86316561 23.0967491  22.92398903 26.89493334 23.06498137\n",
      " 22.79334884 26.86316561 23.47082335 26.89493334 22.92398903 22.79334884\n",
      " 22.94861824 23.21329006 26.89493334 22.92398903 22.79334884 23.27325626\n",
      " 22.92398903 22.78621031 22.97342526 22.77924961 22.92398903 22.97342526\n",
      " 22.92398903 22.92398903 22.92398903 22.92398903 22.92398903 26.89493334\n",
      " 23.0967491  22.79334884 22.79334884 23.27325626 26.89493334 22.92398903\n",
      " 26.04072196 26.92670107 26.86316561 22.92398903 22.92398903 22.92398903\n",
      " 22.79334884 22.79334884 22.97342526 22.92398903 23.47082335 22.79334884\n",
      " 22.92398903 22.78621031 22.77924961 22.92398903 22.92398903 22.92398903\n",
      " 22.92398903 22.92398903 23.0367829  22.92398903 26.89493334 23.06498137\n",
      " 26.89493334 22.92398903 26.86316561 22.92398903 26.89493334 22.92398903\n",
      " 22.92398903 22.92398903 22.92398903 22.92398903 22.92398903]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0 21\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0\n",
      "   0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       4.0\n",
      "           1       0.00      0.00      0.00       2.0\n",
      "           2       0.00      0.00      0.00       4.0\n",
      "           3       0.00      0.00      0.00      11.0\n",
      "           5       0.00      0.00      0.00       3.0\n",
      "           6       0.00      0.00      0.00       3.0\n",
      "           7       0.00      0.00      0.00       4.0\n",
      "           8       0.00      0.00      0.00       3.0\n",
      "           9       0.00      0.00      0.00       4.0\n",
      "          10       0.00      0.00      0.00       3.0\n",
      "          11       0.00      0.00      0.00       2.0\n",
      "          12       0.00      0.00      0.00       2.0\n",
      "          13       0.00      0.00      0.00       1.0\n",
      "          14       0.00      0.00      0.00       1.0\n",
      "          15       0.00      0.00      0.00       1.0\n",
      "          16       0.00      0.00      0.00       4.0\n",
      "          17       0.00      0.00      0.00       2.0\n",
      "          18       0.00      0.00      0.00       2.0\n",
      "          19       0.00      0.00      0.00       3.0\n",
      "          20       0.00      0.00      0.00       3.0\n",
      "          21       0.00      0.00      0.00       5.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          23       0.00      0.00      0.00      34.0\n",
      "          26       0.00      0.00      0.00       2.0\n",
      "          27       0.00      0.00      0.00       4.0\n",
      "\n",
      "    accuracy                           0.00     107.0\n",
      "   macro avg       0.00      0.00      0.00     107.0\n",
      "weighted avg       0.00      0.00      0.00     107.0\n",
      "\n",
      "Y head\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X head\n",
      "[[ 3  1  0  4]\n",
      " [ 3  1  0  4]\n",
      " [ 3  0  0  1]\n",
      " ...\n",
      " [ 0  7  0 18]\n",
      " [ 0  7  0 18]\n",
      " [ 1  6  0  0]]\n",
      "Test Vals!!\n",
      "[[ 3  1  0  4]\n",
      " [ 3  1  0  4]\n",
      " [ 3  0  0  1]\n",
      " ...\n",
      " [ 0  7  0 18]\n",
      " [ 0  7  0 18]\n",
      " [ 1  6  0  0]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[107]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       107\n",
      "\n",
      "    accuracy                           1.00       107\n",
      "   macro avg       1.00      1.00      1.00       107\n",
      "weighted avg       1.00      1.00      1.00       107\n",
      "\n",
      "     cmte_id              cmte_nm cmte_tp cmte_city cmte_st cmte_zip  \\\n",
      "0  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "1  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "2  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "3  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "4  c00343863  ROGERS FOR CONGRESS       H  BRIGHTON      MI    48116   \n",
      "\n",
      "  cmte_dsgn cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0         P                  REP   None             None  ...       None   \n",
      "1         P                  REP   None             None  ...       None   \n",
      "2         P                  REP   None             None  ...       None   \n",
      "3         P                  REP   None             None  ...       None   \n",
      "4         P                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-06-11             667     None    None     None     None   \n",
      "1      1999-06-07             333     None    None     None     None   \n",
      "2      1999-06-18             250     None    None     None     None   \n",
      "3      1999-06-18             250     None    None     None     None   \n",
      "4      1999-06-14             200     None    None     None     None   \n",
      "\n",
      "  memo_text               sub id       party  \n",
      "0      None  3061920110007030000  republican  \n",
      "1      None  3061920110007030000  republican  \n",
      "2      None  3061920110007030000  republican  \n",
      "3      None  3061920110007030000  republican  \n",
      "4      None  3061920110007030000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "X head\n",
      "[[ 3  1  0 ... 20  0  8]\n",
      " [ 3  1  0 ... 20  0  5]\n",
      " [ 3  0  0 ... 23  0  3]\n",
      " ...\n",
      " [ 0  7  0 ... 23  0  7]\n",
      " [ 0  7  0 ... 23  0  7]\n",
      " [ 1  6  0 ... 14  0  7]]\n",
      "0.9906542056074766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cmte_id             cmte_nm cmte_tp cmte_city cmte_st cmte_zip cmte_dsgn  \\\n",
      "0  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "1  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "2  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "3  c00331256  HAYES FOR CONGRESS       H   Concord      NC    28026         P   \n",
      "4  c00331256  HAYES FOR CONGRESS       H   Concord      NC    28026         P   \n",
      "\n",
      "  cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0                  REP   None             None  ...       None   \n",
      "1                  REP   None             None  ...       None   \n",
      "2                  REP   None             None  ...       None   \n",
      "3                  REP   None             None  ...       None   \n",
      "4                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-06-14            1000     None    None     None     None   \n",
      "1      1999-04-13            1000     None    None     None     None   \n",
      "2      1999-04-13            1000     None    None     None     None   \n",
      "3      1999-06-14            1000     None    None     None     None   \n",
      "4      1999-04-13            1000     None    None     None     None   \n",
      "\n",
      "   memo_text               sub id       party  \n",
      "0       None  3061920110007030000  republican  \n",
      "1       None  3061920110007030000  republican  \n",
      "2       None  3061920110007030000  republican  \n",
      "3       None  3061920110007030000  republican  \n",
      "4       None  3061920110007030000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X head\n",
      "[[2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [0 4 0 3 0 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]]\n",
      "Test Vals!!\n",
      "[[2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 1 0 2 2 0]\n",
      " [2 5 0 5 3 0]\n",
      " [2 5 0 5 3 0]\n",
      " [0 4 0 3 0 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [3 3 0 0 4 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]\n",
      " [1 0 0 4 5 0]\n",
      " [1 2 0 1 1 0]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[-0.20606061 -0.20606061  0.01818182 -0.20606061 -0.30909091 -0.20606061\n",
      " -0.19393939 -0.19393939 -0.19393939 -0.19393939 -0.19393939 -0.20606061\n",
      " -0.20606061  0.01818182]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[12  0]\n",
      " [ 2  0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.43      0.50      0.46        14\n",
      "weighted avg       0.73      0.86      0.79        14\n",
      "\n",
      "Y head\n",
      "[2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 0 4 4 4 4 4 4 4 4 4 4 5 1 5 1 5 1 5 1\n",
      " 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1]\n",
      "X head\n",
      "[[2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [0 4 0 3 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]]\n",
      "Test Vals!!\n",
      "[[2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [2 1 0 2 0]\n",
      " [2 5 0 5 0]\n",
      " [2 5 0 5 0]\n",
      " [0 4 0 3 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [3 3 0 0 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]\n",
      " [1 0 0 4 0]\n",
      " [1 2 0 1 0]]\n",
      "[2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 0 4 4 4 4 4 4 4 4 4 4 5 1 5 1 5 1 5 1\n",
      " 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1]\n",
      "[ 1.21678509  1.21678509  1.50890375  1.21678509 -0.10605739  1.21678509\n",
      "  1.20580248  1.43694582  1.20580248  1.20580248  1.43694582  0.5587117\n",
      "  0.5587117   1.50890375]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[1 0 0 0 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 4 0 0 0 0]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07        14\n",
      "   macro avg       0.06      0.17      0.08        14\n",
      "weighted avg       0.02      0.07      0.04        14\n",
      "\n",
      "Y head\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "X head\n",
      "[[2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [0 4 0 3]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]]\n",
      "Test Vals!!\n",
      "[[2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [2 1 0 2]\n",
      " [2 5 0 5]\n",
      " [2 5 0 5]\n",
      " [0 4 0 3]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [3 3 0 0]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]\n",
      " [1 0 0 4]\n",
      " [1 2 0 1]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Prediction!!\n",
      "Confusion Matrix!!\n",
      "[[14]]\n",
      "Classificaiton Report!!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "     cmte_id             cmte_nm cmte_tp cmte_city cmte_st cmte_zip cmte_dsgn  \\\n",
      "0  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "1  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "2  c00331256  HAYES FOR CONGRESS       H   CONCORD      NC    28026         P   \n",
      "3  c00331256  HAYES FOR CONGRESS       H   Concord      NC    28026         P   \n",
      "4  c00331256  HAYES FOR CONGRESS       H   Concord      NC    28026         P   \n",
      "\n",
      "  cmte_pty_affiliation org_tp connected_org_nm  ... occupation  \\\n",
      "0                  REP   None             None  ...       None   \n",
      "1                  REP   None             None  ...       None   \n",
      "2                  REP   None             None  ...       None   \n",
      "3                  REP   None             None  ...       None   \n",
      "4                  REP   None             None  ...       None   \n",
      "\n",
      "   transaction_dt transaction_amt other_id tran_id file_num  memo_cd  \\\n",
      "0      1999-06-14            1000     None    None     None     None   \n",
      "1      1999-04-13            1000     None    None     None     None   \n",
      "2      1999-04-13            1000     None    None     None     None   \n",
      "3      1999-06-14            1000     None    None     None     None   \n",
      "4      1999-04-13            1000     None    None     None     None   \n",
      "\n",
      "   memo_text               sub id       party  \n",
      "0       None  3061920110007030000  republican  \n",
      "1       None  3061920110007030000  republican  \n",
      "2       None  3061920110007030000  republican  \n",
      "3       None  3061920110007030000  republican  \n",
      "4       None  3061920110007030000  republican  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Y head\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "X head\n",
      "[[2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 1 0 2 2 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [2 5 0 5 3 0 0]\n",
      " [0 4 0 3 0 0 0]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [3 3 0 0 4 0 1]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]\n",
      " [1 0 0 4 5 0 0]\n",
      " [1 2 0 1 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/C454479/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e19c65de81d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run the main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-cef45b551625>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#TODO Once we have party, then enable logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdonation_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonor_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#Get a list of DFs that for election election year for that state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-1de40a37d75e>\u001b[0m in \u001b[0;36mdonation_logistic_regression\u001b[0;34m(donor_df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Run logistic regression to test if we can classify the party\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrun_logistic_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonor_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-12e2079c4522>\u001b[0m in \u001b[0;36mrun_logistic_regression_params\u001b[0;34m(df, sml_params, sml_cols)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_logistic_regression_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_sml_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msml_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-1a103945d2f2>\u001b[0m in \u001b[0;36mrun_sml_params\u001b[0;34m(df, sml_params, sml_cols, model_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m#Run Logistic Regresion Model on X,y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mrun_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-e92161ac8fb3>\u001b[0m in \u001b[0;36mrun_logistic_regression\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Split the preprocessed data into a training and testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m78\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2141\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m   1328\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1660\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "#Run the main loop\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
